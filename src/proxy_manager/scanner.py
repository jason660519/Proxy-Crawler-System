"""ä»£ç†æƒæèˆ‡é©—è­‰æ¨¡çµ„

å¯¦æ–½é«˜ç´šä»£ç†æƒææŠ€è¡“ï¼š
- é«˜é€Ÿç«¯å£æƒæï¼ˆZMap/Masscan é¢¨æ ¼ï¼‰
- å¤šå±¤ä»£ç†é©—è­‰
- åŒ¿ååº¦æª¢æ¸¬
- åœ°ç†ä½ç½®é©—è­‰
- æ€§èƒ½åŸºæº–æ¸¬è©¦
"""

import asyncio
import aiohttp
import socket
import struct
import time
import random
from typing import List, Optional, Dict, Any, Tuple, Set
from datetime import datetime, timedelta
import logging
from concurrent.futures import ThreadPoolExecutor
import ipaddress
from urllib.parse import urlparse
import json

from .models import ProxyNode, ProxyProtocol, ProxyAnonymity, ProxyStatus, ProxySpeed
from .intelligent_detection import IntelligentProxyDetector, DetectionResult, BenchmarkResult
from .geolocation_enhanced import EnhancedGeolocationDetector, GeolocationInfo
from .quality_assessment import ProxyQualityAssessor, QualityMetrics, QualityGrade
from .zmap_integration import ZMapIntegration, IntelligentTargetDiscovery

logger = logging.getLogger(__name__)


class ProxyScanner:
    """é«˜ç´šä»£ç†æƒæå™¨
    
    æä¾›å¤šç¨®æƒæå’Œé©—è­‰æ–¹æ³•
    """
    
    def __init__(self, max_concurrent: int = 100, timeout: float = 10.0):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.session: Optional[aiohttp.ClientSession] = None
        self.executor = ThreadPoolExecutor(max_workers=50)
        
        # æ¸¬è©¦ URL é…ç½®
        self.test_urls = [
            "http://httpbin.org/ip",
            "https://api.ipify.org?format=json",
            "http://icanhazip.com",
            "https://checkip.amazonaws.com",
            "http://ip-api.com/json"
        ]
        
        # åŒ¿ååº¦æª¢æ¸¬ URL
        self.anonymity_test_urls = [
            "http://httpbin.org/headers",
            "https://httpbin.org/headers"
        ]
        
        # çµ±è¨ˆä¿¡æ¯
        self.scan_stats = {
            "total_scanned": 0,
            "successful_connections": 0,
            "failed_connections": 0,
            "timeout_errors": 0,
            "connection_errors": 0
        }
    
    async def _get_session(self) -> aiohttp.ClientSession:
        """ç²å–æˆ–å‰µå»º HTTP æœƒè©±"""
        if not self.session:
            connector = aiohttp.TCPConnector(
                limit=self.max_concurrent,
                limit_per_host=20,
                ttl_dns_cache=300,
                use_dns_cache=True,
                enable_cleanup_closed=True
            )
            
            timeout = aiohttp.ClientTimeout(
                total=self.timeout,
                connect=self.timeout / 2,
                sock_read=self.timeout / 2
            )
            
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
            )
        
        return self.session
    
    async def scan_proxy_batch(self, proxies: List[ProxyNode]) -> List[ProxyNode]:
        """æ‰¹é‡æƒæä»£ç†"""
        logger.info(f"ğŸ” é–‹å§‹æƒæ {len(proxies)} å€‹ä»£ç†...")
        
        # å‰µå»ºæƒæä»»å‹™
        semaphore = asyncio.Semaphore(self.max_concurrent)
        tasks = [self._scan_single_proxy(proxy, semaphore) for proxy in proxies]
        
        # åŸ·è¡Œæƒæ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†çµæœ
        scanned_proxies = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.debug(f"ä»£ç†æƒæç•°å¸¸ {proxies[i].host}:{proxies[i].port}: {result}")
                proxies[i].status = ProxyStatus.FAILED
                self.scan_stats["failed_connections"] += 1
            else:
                scanned_proxies.append(result)
        
        # çµ±è¨ˆ
        active_count = len([p for p in scanned_proxies if p.status == ProxyStatus.ACTIVE])
        logger.info(f"âœ… æƒæå®Œæˆï¼š{active_count}/{len(proxies)} å€‹ä»£ç†å¯ç”¨")
        
        return scanned_proxies
    
    async def _scan_single_proxy(self, proxy: ProxyNode, semaphore: asyncio.Semaphore) -> ProxyNode:
        """æƒæå–®å€‹ä»£ç†"""
        async with semaphore:
            self.scan_stats["total_scanned"] += 1
            
            # 1. åŸºæœ¬é€£æ¥æ¸¬è©¦
            if not await self._test_basic_connection(proxy):
                proxy.status = ProxyStatus.FAILED
                return proxy
            
            # 2. HTTP åŠŸèƒ½æ¸¬è©¦
            if not await self._test_http_functionality(proxy):
                proxy.status = ProxyStatus.FAILED
                return proxy
            
            # 3. åŒ¿ååº¦æª¢æ¸¬
            anonymity = await self._detect_anonymity(proxy)
            proxy.anonymity = anonymity
            
            # 4. é€Ÿåº¦æ¸¬è©¦
            speed = await self._measure_speed(proxy)
            proxy.speed = speed
            
            # 5. åœ°ç†ä½ç½®æª¢æ¸¬
            await self._detect_geolocation(proxy)
            
            # æ›´æ–°ç‹€æ…‹
            proxy.status = ProxyStatus.ACTIVE
            proxy.last_checked = datetime.now()
            self.scan_stats["successful_connections"] += 1
            
            return proxy
    
    async def _test_basic_connection(self, proxy: ProxyNode) -> bool:
        """åŸºæœ¬é€£æ¥æ¸¬è©¦"""
        try:
            # TCP é€£æ¥æ¸¬è©¦
            if proxy.protocol in [ProxyProtocol.SOCKS4, ProxyProtocol.SOCKS5]:
                return await self._test_socks_connection(proxy)
            else:
                return await self._test_http_connection(proxy)
        
        except Exception as e:
            logger.debug(f"åŸºæœ¬é€£æ¥æ¸¬è©¦å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            self.scan_stats["connection_errors"] += 1
            return False
    
    async def _test_socks_connection(self, proxy: ProxyNode) -> bool:
        """SOCKS ä»£ç†é€£æ¥æ¸¬è©¦"""
        try:
            # ä½¿ç”¨ asyncio é€²è¡Œ SOCKS æ¡æ‰‹æ¸¬è©¦
            reader, writer = await asyncio.wait_for(
                asyncio.open_connection(proxy.host, proxy.port),
                timeout=self.timeout / 2
            )
            
            if proxy.protocol == ProxyProtocol.SOCKS4:
                # SOCKS4 æ¡æ‰‹
                request = struct.pack(">BBH4s", 4, 1, 80, socket.inet_aton("8.8.8.8")) + b"\x00"
            else:
                # SOCKS5 æ¡æ‰‹
                request = b"\x05\x01\x00"  # ç‰ˆæœ¬5ï¼Œ1å€‹æ–¹æ³•ï¼Œç„¡èªè­‰
            
            writer.write(request)
            await writer.drain()
            
            response = await asyncio.wait_for(reader.read(1024), timeout=2)
            writer.close()
            await writer.wait_closed()
            
            return len(response) > 0
        
        except Exception as e:
            logger.debug(f"SOCKS é€£æ¥æ¸¬è©¦å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            return False
    
    async def _test_http_connection(self, proxy: ProxyNode) -> bool:
        """HTTP ä»£ç†é€£æ¥æ¸¬è©¦"""
        try:
            session = await self._get_session()
            proxy_url = f"http://{proxy.host}:{proxy.port}"
            
            async with session.get(
                "http://httpbin.org/ip",
                proxy=proxy_url,
                timeout=aiohttp.ClientTimeout(total=self.timeout / 2)
            ) as response:
                return response.status == 200
        
        except asyncio.TimeoutError:
            self.scan_stats["timeout_errors"] += 1
            return False
        except Exception as e:
            logger.debug(f"HTTP é€£æ¥æ¸¬è©¦å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            return False
    
    async def _test_http_functionality(self, proxy: ProxyNode) -> bool:
        """HTTP åŠŸèƒ½å®Œæ•´æ€§æ¸¬è©¦"""
        try:
            session = await self._get_session()
            proxy_url = f"http://{proxy.host}:{proxy.port}"
            
            # æ¸¬è©¦å¤šå€‹ URL
            for test_url in self.test_urls[:2]:  # åªæ¸¬è©¦å‰å…©å€‹ä»¥ç¯€çœæ™‚é–“
                try:
                    async with session.get(
                        test_url,
                        proxy=proxy_url,
                        timeout=aiohttp.ClientTimeout(total=self.timeout)
                    ) as response:
                        if response.status == 200:
                            return True
                except:
                    continue
            
            return False
        
        except Exception as e:
            logger.debug(f"HTTP åŠŸèƒ½æ¸¬è©¦å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            return False
    
    async def _detect_anonymity(self, proxy: ProxyNode) -> ProxyAnonymity:
        """æª¢æ¸¬ä»£ç†åŒ¿ååº¦"""
        try:
            session = await self._get_session()
            proxy_url = f"http://{proxy.host}:{proxy.port}"
            
            # ç²å–åŸå§‹ IPï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰
            try:
                async with session.get("http://httpbin.org/ip", timeout=aiohttp.ClientTimeout(total=5)) as response:
                    if response.status == 200:
                        original_data = await response.json()
                        original_ip = original_data.get("origin", "").split(",")[0].strip()
                    else:
                        original_ip = None
            except:
                original_ip = None
            
            # é€šéä»£ç†ç²å– headers
            async with session.get(
                "http://httpbin.org/headers",
                proxy=proxy_url,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                if response.status != 200:
                    return ProxyAnonymity.UNKNOWN
                
                data = await response.json()
                headers = data.get("headers", {})
                
                # æª¢æŸ¥æ˜¯å¦æ´©éœ²åŸå§‹ IP
                forwarded_headers = [
                    "X-Forwarded-For", "X-Real-Ip", "X-Originating-Ip",
                    "Client-Ip", "Via", "Forwarded"
                ]
                
                has_forwarded = any(header in headers for header in forwarded_headers)
                
                # æª¢æŸ¥ User-Agent æ˜¯å¦è¢«ä¿®æ”¹
                user_agent = headers.get("User-Agent", "")
                is_ua_modified = "proxy" in user_agent.lower() or "squid" in user_agent.lower()
                
                # åˆ¤æ–·åŒ¿ååº¦
                if has_forwarded or is_ua_modified:
                    if original_ip and any(original_ip in str(headers.get(h, "")) for h in forwarded_headers):
                        return ProxyAnonymity.TRANSPARENT
                    else:
                        return ProxyAnonymity.ANONYMOUS
                else:
                    return ProxyAnonymity.ELITE
        
        except Exception as e:
            logger.debug(f"åŒ¿ååº¦æª¢æ¸¬å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            return ProxyAnonymity.UNKNOWN
    
    async def _measure_speed(self, proxy: ProxyNode) -> ProxySpeed:
        """æ¸¬é‡ä»£ç†é€Ÿåº¦"""
        try:
            session = await self._get_session()
            proxy_url = f"http://{proxy.host}:{proxy.port}"
            
            # æ¸¬è©¦å°æ–‡ä»¶ä¸‹è¼‰é€Ÿåº¦
            start_time = time.time()
            
            async with session.get(
                "http://httpbin.org/bytes/1024",  # ä¸‹è¼‰ 1KB æ•¸æ“š
                proxy=proxy_url,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                if response.status == 200:
                    await response.read()
                    end_time = time.time()
                    
                    response_time = end_time - start_time
                    
                    # æ ¹æ“šéŸ¿æ‡‰æ™‚é–“åˆ†é¡é€Ÿåº¦
                    if response_time < 1.0:
                        return ProxySpeed.FAST
                    elif response_time < 3.0:
                        return ProxySpeed.MEDIUM
                    else:
                        return ProxySpeed.SLOW
                else:
                    return ProxySpeed.UNKNOWN
        
        except Exception as e:
            logger.debug(f"é€Ÿåº¦æ¸¬è©¦å¤±æ•— {proxy.host}:{proxy.port}: {e}")
            return ProxySpeed.UNKNOWN
    
    async def _detect_geolocation(self, proxy: ProxyNode):
        """æª¢æ¸¬ä»£ç†åœ°ç†ä½ç½®"""
        try:
            session = await self._get_session()
            proxy_url = f"http://{proxy.host}:{proxy.port}"
            
            # ä½¿ç”¨ ip-api.com ç²å–åœ°ç†ä½ç½®ä¿¡æ¯
            async with session.get(
                "http://ip-api.com/json",
                proxy=proxy_url,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if data.get("status") == "success":
                        proxy.country = data.get("country")
                        proxy.region = data.get("regionName")
                        proxy.city = data.get("city")
                        proxy.isp = data.get("isp")
                        
                        # æ›´æ–°å…ƒæ•¸æ“š
                        if not proxy.metadata:
                            proxy.metadata = {}
                        
                        proxy.metadata.update({
                            "geolocation": {
                                "lat": data.get("lat"),
                                "lon": data.get("lon"),
                                "timezone": data.get("timezone"),
                                "as": data.get("as"),
                                "query": data.get("query")  # å¯¦éš› IP
                            }
                        })
        
        except Exception as e:
            logger.debug(f"åœ°ç†ä½ç½®æª¢æ¸¬å¤±æ•— {proxy.host}:{proxy.port}: {e}")
    
    def get_scan_stats(self) -> Dict[str, Any]:
        """ç²å–æƒæçµ±è¨ˆä¿¡æ¯"""
        total = self.scan_stats["total_scanned"]
        if total == 0:
            return self.scan_stats
        
        return {
            **self.scan_stats,
            "success_rate": (self.scan_stats["successful_connections"] / total) * 100,
            "failure_rate": (self.scan_stats["failed_connections"] / total) * 100,
            "timeout_rate": (self.scan_stats["timeout_errors"] / total) * 100
        }
    
    async def close(self):
        """é—œé–‰æƒæå™¨"""
        if self.session:
            await self.session.close()
            self.session = None
        
        self.executor.shutdown(wait=True)
        logger.info("âœ… ä»£ç†æƒæå™¨å·²é—œé–‰")


class FastPortScanner:
    """é«˜é€Ÿç«¯å£æƒæå™¨
    
    æ¨¡æ“¬ ZMap/Masscan çš„é«˜é€ŸæƒææŠ€è¡“
    """
    
    def __init__(self, max_concurrent: int = 1000, timeout: float = 3.0):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.common_proxy_ports = [
            80, 8080, 3128, 8000, 8888, 9999, 8118, 8123, 8181,
            1080, 1081, 1085, 4145, 5678,  # SOCKS
            443, 8443, 8843,  # HTTPS
            3129, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8089,
            9000, 9001, 9002, 9003, 9080, 9090, 9091, 9092, 9093
        ]
    
    async def scan_ip_range(self, ip_range: str, ports: Optional[List[int]] = None) -> List[Tuple[str, int]]:
        """æƒæ IP ç¯„åœçš„é–‹æ”¾ç«¯å£"""
        if ports is None:
            ports = self.common_proxy_ports
        
        # è§£æ IP ç¯„åœ
        try:
            network = ipaddress.ip_network(ip_range, strict=False)
            ips = [str(ip) for ip in network.hosts()]
        except ValueError:
            # å–®å€‹ IP
            ips = [ip_range]
        
        logger.info(f"ğŸ” é–‹å§‹æƒæ {len(ips)} å€‹ IP çš„ {len(ports)} å€‹ç«¯å£...")
        
        # å‰µå»ºæƒæä»»å‹™
        semaphore = asyncio.Semaphore(self.max_concurrent)
        tasks = []
        
        for ip in ips:
            for port in ports:
                tasks.append(self._scan_port(ip, port, semaphore))
        
        # åŸ·è¡Œæƒæ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†é–‹æ”¾çš„ç«¯å£
        open_ports = []
        for result in results:
            if isinstance(result, tuple) and result[2]:  # (ip, port, is_open)
                open_ports.append((result[0], result[1]))
        
        logger.info(f"âœ… ç™¼ç¾ {len(open_ports)} å€‹é–‹æ”¾ç«¯å£")
        return open_ports
    
    async def _scan_port(self, ip: str, port: int, semaphore: asyncio.Semaphore) -> Tuple[str, int, bool]:
        """æƒæå–®å€‹ç«¯å£"""
        async with semaphore:
            try:
                # TCP é€£æ¥æ¸¬è©¦
                reader, writer = await asyncio.wait_for(
                    asyncio.open_connection(ip, port),
                    timeout=self.timeout
                )
                
                writer.close()
                await writer.wait_closed()
                
                return (ip, port, True)
            
            except Exception:
                return (ip, port, False)
    
    async def discover_proxies_in_range(self, ip_range: str) -> List[ProxyNode]:
        """åœ¨ IP ç¯„åœå…§ç™¼ç¾æ½›åœ¨ä»£ç†"""
        open_ports = await self.scan_ip_range(ip_range)
        
        proxies = []
        for ip, port in open_ports:
            # æ ¹æ“šç«¯å£æ¨æ¸¬å”è­°
            if port in [1080, 1081, 4145, 5678]:
                protocol = ProxyProtocol.SOCKS5
            elif port in [1085]:
                protocol = ProxyProtocol.SOCKS4
            elif port in [443, 8443, 8843]:
                protocol = ProxyProtocol.HTTPS
            else:
                protocol = ProxyProtocol.HTTP
            
            proxy = ProxyNode(
                host=ip,
                port=port,
                protocol=protocol,
                status=ProxyStatus.INACTIVE,
                source="fast-scanner",
                tags=["discovered", "port-scan"]
            )
            
            proxies.append(proxy)
        
        logger.info(f"ğŸ¯ åœ¨ç¯„åœ {ip_range} ç™¼ç¾ {len(proxies)} å€‹æ½›åœ¨ä»£ç†")
        return proxies


class ProxyValidator:
    """ä»£ç†é©—è­‰å™¨
    
    æä¾›å…¨é¢çš„ä»£ç†é©—è­‰åŠŸèƒ½
    """
    
    def __init__(self, scanner: ProxyScanner):
        self.scanner = scanner
        self.validation_rules = {
            "min_speed": ProxySpeed.SLOW,
            "required_anonymity": ProxyAnonymity.TRANSPARENT,
            "max_response_time": 10.0,
            "required_countries": None,  # None = æ‰€æœ‰åœ‹å®¶
            "blocked_countries": ["CN", "RU"],  # ç¤ºä¾‹ï¼šé˜»æ­¢æŸäº›åœ‹å®¶
            "required_protocols": None  # None = æ‰€æœ‰å”è­°
        }
    
    def set_validation_rules(self, rules: Dict[str, Any]):
        """è¨­ç½®é©—è­‰è¦å‰‡"""
        self.validation_rules.update(rules)
    
    async def validate_proxies(self, proxies: List[ProxyNode]) -> List[ProxyNode]:
        """é©—è­‰ä»£ç†åˆ—è¡¨"""
        logger.info(f"ğŸ” é–‹å§‹é©—è­‰ {len(proxies)} å€‹ä»£ç†...")
        
        # é¦–å…ˆé€²è¡Œæƒæ
        scanned_proxies = await self.scanner.scan_proxy_batch(proxies)
        
        # ç„¶å¾Œæ‡‰ç”¨é©—è­‰è¦å‰‡
        validated_proxies = []
        for proxy in scanned_proxies:
            if self._meets_validation_criteria(proxy):
                validated_proxies.append(proxy)
        
        logger.info(f"âœ… {len(validated_proxies)}/{len(proxies)} å€‹ä»£ç†é€šéé©—è­‰")
        return validated_proxies
    
    def _meets_validation_criteria(self, proxy: ProxyNode) -> bool:
        """æª¢æŸ¥ä»£ç†æ˜¯å¦ç¬¦åˆé©—è­‰æ¨™æº–"""
        # å¿…é ˆæ˜¯æ´»èºç‹€æ…‹
        if proxy.status != ProxyStatus.ACTIVE:
            return False
        
        # é€Ÿåº¦æª¢æŸ¥
        if proxy.speed and proxy.speed.value < self.validation_rules["min_speed"].value:
            return False
        
        # åŒ¿ååº¦æª¢æŸ¥
        if proxy.anonymity and proxy.anonymity.value < self.validation_rules["required_anonymity"].value:
            return False
        
        # åœ‹å®¶æª¢æŸ¥
        if self.validation_rules["required_countries"]:
            if proxy.country not in self.validation_rules["required_countries"]:
                return False
        
        if self.validation_rules["blocked_countries"]:
            if proxy.country in self.validation_rules["blocked_countries"]:
                return False
        
        # å”è­°æª¢æŸ¥
        if self.validation_rules["required_protocols"]:
            if proxy.protocol not in self.validation_rules["required_protocols"]:
                return False
        
        return True
    
    def get_validation_report(self, original_proxies: List[ProxyNode], validated_proxies: List[ProxyNode]) -> Dict[str, Any]:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        total_original = len(original_proxies)
        total_validated = len(validated_proxies)
        
        # æŒ‰ç‹€æ…‹çµ±è¨ˆ
        status_counts = {}
        for proxy in original_proxies:
            status = proxy.status.name
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # æŒ‰å”è­°çµ±è¨ˆ
        protocol_counts = {}
        for proxy in validated_proxies:
            protocol = proxy.protocol.name
            protocol_counts[protocol] = protocol_counts.get(protocol, 0) + 1
        
        # æŒ‰åœ‹å®¶çµ±è¨ˆ
        country_counts = {}
        for proxy in validated_proxies:
            country = proxy.country or "Unknown"
            country_counts[country] = country_counts.get(country, 0) + 1
        
        return {
            "total_original": total_original,
            "total_validated": total_validated,
            "validation_rate": (total_validated / total_original * 100) if total_original > 0 else 0,
            "status_distribution": status_counts,
            "protocol_distribution": protocol_counts,
            "country_distribution": country_counts,
            "validation_rules": self.validation_rules,
            "scanner_stats": self.scanner.get_scan_stats()
        }


class EnhancedProxyScanner:
    """å¢å¼·ä»£ç†æƒæå™¨
    
    æ•´åˆæ‰€æœ‰ç¬¬äºŒéšæ®µåŠŸèƒ½ï¼š
    - ZMap æ•´åˆ
    - æ™ºèƒ½ä»£ç†æ¢æ¸¬
    - åœ°ç†ä½ç½®å¢å¼·æª¢æ¸¬
    - è³ªé‡è©•ä¼°
    """
    
    def __init__(self, max_concurrent: int = 100, timeout: float = 10.0):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        
        # åˆå§‹åŒ–å„å€‹çµ„ä»¶
        self.basic_scanner = ProxyScanner(max_concurrent, timeout)
        self.port_scanner = FastPortScanner(max_concurrent, timeout)
        self.intelligent_detector = IntelligentProxyDetector()
        self.geolocation_detector = EnhancedGeolocationDetector()
        self.quality_assessor = ProxyQualityAssessor()
        self.zmap_integration = ZMapIntegration()
        self.target_discovery = IntelligentTargetDiscovery(self.zmap_integration)
        
        # çµ±è¨ˆä¿¡æ¯
        self.enhanced_stats = {
            "total_discovered": 0,
            "total_analyzed": 0,
            "high_quality_count": 0,
            "geographic_coverage": {},
            "anonymity_distribution": {},
            "performance_metrics": {}
        }
    
    async def comprehensive_scan(self, 
                               targets: Optional[List[str]] = None,
                               ip_ranges: Optional[List[str]] = None,
                               existing_proxies: Optional[List[ProxyNode]] = None,
                               enable_zmap: bool = False,
                               enable_intelligence: bool = True,
                               enable_quality_assessment: bool = True) -> Dict[str, Any]:
        """å…¨é¢æƒæ
        
        Args:
            targets: ç›®æ¨™ä¸»æ©Ÿåˆ—è¡¨
            ip_ranges: IP ç¯„åœåˆ—è¡¨
            existing_proxies: ç¾æœ‰ä»£ç†åˆ—è¡¨
            enable_zmap: æ˜¯å¦å•Ÿç”¨ ZMap æƒæ
            enable_intelligence: æ˜¯å¦å•Ÿç”¨æ™ºèƒ½æª¢æ¸¬
            enable_quality_assessment: æ˜¯å¦å•Ÿç”¨è³ªé‡è©•ä¼°
            
        Returns:
            æƒæçµæœå­—å…¸
        """
        logger.info("ğŸš€ é–‹å§‹å¢å¼·ä»£ç†æƒæ...")
        
        all_proxies = []
        scan_results = {
            "discovered_proxies": [],
            "analyzed_proxies": [],
            "quality_metrics": [],
            "geographic_info": [],
            "detection_results": [],
            "benchmark_results": [],
            "statistics": {}
        }
        
        try:
            # 1. ç›®æ¨™ç™¼ç¾éšæ®µ
            if targets or ip_ranges:
                discovered_proxies = await self._discover_targets(targets, ip_ranges, enable_zmap)
                all_proxies.extend(discovered_proxies)
                scan_results["discovered_proxies"] = discovered_proxies
                self.enhanced_stats["total_discovered"] += len(discovered_proxies)
            
            # 2. æ·»åŠ ç¾æœ‰ä»£ç†
            if existing_proxies:
                all_proxies.extend(existing_proxies)
            
            if not all_proxies:
                logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ä»£ç†é€²è¡Œæƒæ")
                return scan_results
            
            # 3. åŸºç¤æƒæ
            logger.info(f"ğŸ” é–‹å§‹åŸºç¤æƒæ {len(all_proxies)} å€‹ä»£ç†...")
            scanned_proxies = await self.basic_scanner.scan_proxy_batch(all_proxies)
            active_proxies = [p for p in scanned_proxies if p.status == ProxyStatus.ACTIVE]
            
            logger.info(f"âœ… åŸºç¤æƒæå®Œæˆï¼š{len(active_proxies)} å€‹æ´»èºä»£ç†")
            
            if not active_proxies:
                logger.warning("âš ï¸ æ²’æœ‰ç™¼ç¾æ´»èºçš„ä»£ç†")
                scan_results["analyzed_proxies"] = scanned_proxies
                return scan_results
            
            # 4. æ™ºèƒ½æª¢æ¸¬éšæ®µ
            if enable_intelligence:
                logger.info("ğŸ§  é–‹å§‹æ™ºèƒ½æª¢æ¸¬éšæ®µ...")
                detection_results, benchmark_results = await self._intelligent_analysis(active_proxies)
                scan_results["detection_results"] = detection_results
                scan_results["benchmark_results"] = benchmark_results
            else:
                detection_results = [None] * len(active_proxies)
                benchmark_results = [None] * len(active_proxies)
            
            # 5. åœ°ç†ä½ç½®å¢å¼·æª¢æ¸¬
            logger.info("ğŸŒ é–‹å§‹åœ°ç†ä½ç½®å¢å¼·æª¢æ¸¬...")
            geographic_info = await self._enhanced_geolocation_analysis(active_proxies)
            scan_results["geographic_info"] = geographic_info
            
            # 6. è³ªé‡è©•ä¼°éšæ®µ
            if enable_quality_assessment:
                logger.info("ğŸ“Š é–‹å§‹è³ªé‡è©•ä¼°éšæ®µ...")
                quality_metrics = await self._quality_assessment_analysis(
                    active_proxies, detection_results, benchmark_results
                )
                scan_results["quality_metrics"] = quality_metrics
                
                # çµ±è¨ˆé«˜è³ªé‡ä»£ç†
                high_quality_count = len([
                    m for m in quality_metrics 
                    if m.quality_grade in [QualityGrade.EXCELLENT, QualityGrade.GOOD]
                ])
                self.enhanced_stats["high_quality_count"] = high_quality_count
            
            # 7. æ›´æ–°çµ±è¨ˆä¿¡æ¯
            self.enhanced_stats["total_analyzed"] = len(active_proxies)
            self._update_enhanced_statistics(active_proxies, scan_results)
            
            scan_results["analyzed_proxies"] = active_proxies
            scan_results["statistics"] = self.get_enhanced_statistics()
            
            logger.info(f"ğŸ‰ å¢å¼·æƒæå®Œæˆï¼åˆ†æäº† {len(active_proxies)} å€‹ä»£ç†")
            
        except Exception as e:
            logger.error(f"âŒ å¢å¼·æƒæéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            scan_results["error"] = str(e)
        
        return scan_results
    
    async def _discover_targets(self, 
                              targets: Optional[List[str]], 
                              ip_ranges: Optional[List[str]], 
                              enable_zmap: bool) -> List[ProxyNode]:
        """ç›®æ¨™ç™¼ç¾"""
        discovered_proxies = []
        
        # æ™ºèƒ½ç›®æ¨™ç™¼ç¾
        if targets:
            logger.info(f"ğŸ¯ ä½¿ç”¨æ™ºèƒ½ç›®æ¨™ç™¼ç¾åˆ†æ {len(targets)} å€‹ç›®æ¨™...")
            intelligent_targets = await self.target_discovery.generate_smart_targets(
                targets, intelligence_sources=['shodan', 'censys']
            )
            # å°‡ç›®æ¨™å­—ç¬¦ä¸²è½‰æ›ç‚ºä»£ç†ç¯€é»ï¼ˆé€™è£¡éœ€è¦é€²ä¸€æ­¥æƒæï¼‰
            for target in intelligent_targets:
                # é€™è£¡æ‡‰è©²èª¿ç”¨æƒææ–¹æ³•ä¾†ç™¼ç¾å¯¦éš›çš„ä»£ç†
                pass
        
        # IP ç¯„åœæƒæ
        if ip_ranges:
            for ip_range in ip_ranges:
                logger.info(f"ğŸ” æƒæ IP ç¯„åœ: {ip_range}")
                
                if enable_zmap:
                    # ä½¿ç”¨ ZMap é€²è¡Œé«˜é€Ÿæƒæ
                    zmap_results = await self.zmap_integration.scan_range(
                        ip_range, ports=[80, 8080, 3128, 1080]
                    )
                    discovered_proxies.extend(zmap_results)
                else:
                    # ä½¿ç”¨å…§å»ºå¿«é€Ÿæƒæå™¨
                    range_proxies = await self.port_scanner.discover_proxies_in_range(ip_range)
                    discovered_proxies.extend(range_proxies)
        
        return discovered_proxies
    
    async def _intelligent_analysis(self, proxies: List[ProxyNode]) -> Tuple[List[DetectionResult], List[BenchmarkResult]]:
        """æ™ºèƒ½åˆ†æ"""
        detection_results = []
        benchmark_results = []
        
        # æ‰¹é‡æ™ºèƒ½æª¢æ¸¬
        semaphore = asyncio.Semaphore(self.max_concurrent // 2)  # æ¸›å°‘ä¸¦ç™¼ä»¥é¿å…éè¼‰
        
        async def analyze_proxy(proxy: ProxyNode) -> Tuple[Optional[DetectionResult], Optional[BenchmarkResult]]:
            async with semaphore:
                try:
                    # æ™ºèƒ½æª¢æ¸¬
                    detection_result = await self.intelligent_detector.detect_proxy(proxy, comprehensive=True)
                    
                    # æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆåƒ…å°é«˜è³ªé‡ä»£ç†é€²è¡Œï¼‰
                    benchmark_result = None
                    if detection_result and detection_result.is_working and detection_result.success_rate > 0.7:
                        benchmark_result = await self.intelligent_detector.benchmark_proxy(proxy)
                    
                    return detection_result, benchmark_result
                    
                except Exception as e:
                    logger.debug(f"æ™ºèƒ½åˆ†æå¤±æ•— {proxy.host}:{proxy.port}: {e}")
                    return None, None
        
        # åŸ·è¡Œåˆ†æ
        tasks = [analyze_proxy(proxy) for proxy in proxies]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, tuple):
                detection_result, benchmark_result = result
                detection_results.append(detection_result)
                benchmark_results.append(benchmark_result)
            else:
                detection_results.append(None)
                benchmark_results.append(None)
        
        return detection_results, benchmark_results
    
    async def _enhanced_geolocation_analysis(self, proxies: List[ProxyNode]) -> List[GeolocationInfo]:
        """å¢å¼·åœ°ç†ä½ç½®åˆ†æ"""
        geographic_info = []
        
        # æ‰¹é‡åœ°ç†ä½ç½®æª¢æ¸¬
        proxy_ips = [proxy.host for proxy in proxies]
        geo_results = await self.geolocation_detector.batch_detect_locations(proxy_ips)
        
        for proxy in proxies:
            if proxy.host in geo_results:
                geo_info = geo_results[proxy.host]
                
                # æ›´æ–°ä»£ç†çš„åœ°ç†ä¿¡æ¯
                proxy.country = geo_info.country_code
                proxy.region = geo_info.region
                proxy.city = geo_info.city
                proxy.isp = geo_info.isp
                
                # æ›´æ–°å…ƒæ•¸æ“š
                if not proxy.metadata:
                    proxy.metadata = {}
                
                proxy.metadata["enhanced_geolocation"] = {
                    "latitude": geo_info.latitude,
                    "longitude": geo_info.longitude,
                    "timezone": geo_info.timezone,
                    "asn": geo_info.asn,
                    "organization": geo_info.organization,
                    "accuracy_radius": geo_info.accuracy_radius,
                    "is_vpn": geo_info.is_vpn,
                    "is_tor": geo_info.is_tor,
                    "threat_level": geo_info.threat_level
                }
                
                geographic_info.append(geo_info)
            else:
                geographic_info.append(None)
        
        return geographic_info
    
    async def _quality_assessment_analysis(self, 
                                         proxies: List[ProxyNode],
                                         detection_results: List[Optional[DetectionResult]],
                                         benchmark_results: List[Optional[BenchmarkResult]]) -> List[QualityMetrics]:
        """è³ªé‡è©•ä¼°åˆ†æ"""
        # æº–å‚™è©•ä¼°æ•¸æ“š
        assessment_data = []
        for i, proxy in enumerate(proxies):
            detection_result = detection_results[i] if i < len(detection_results) else None
            benchmark_result = benchmark_results[i] if i < len(benchmark_results) else None
            assessment_data.append((proxy, detection_result, benchmark_result))
        
        # æ‰¹é‡è³ªé‡è©•ä¼°
        quality_metrics = self.quality_assessor.batch_assess_quality(assessment_data)
        
        return quality_metrics
    
    def _update_enhanced_statistics(self, proxies: List[ProxyNode], scan_results: Dict[str, Any]):
        """æ›´æ–°å¢å¼·çµ±è¨ˆä¿¡æ¯"""
        # åœ°ç†è¦†è“‹çµ±è¨ˆ
        country_counts = {}
        for proxy in proxies:
            country = proxy.country or "Unknown"
            country_counts[country] = country_counts.get(country, 0) + 1
        self.enhanced_stats["geographic_coverage"] = country_counts
        
        # åŒ¿åæ€§åˆ†ä½ˆçµ±è¨ˆ
        anonymity_counts = {}
        for proxy in proxies:
            anonymity = proxy.anonymity.name if proxy.anonymity else "Unknown"
            anonymity_counts[anonymity] = anonymity_counts.get(anonymity, 0) + 1
        self.enhanced_stats["anonymity_distribution"] = anonymity_counts
        
        # æ€§èƒ½æŒ‡æ¨™çµ±è¨ˆ
        if "benchmark_results" in scan_results:
            benchmark_results = [r for r in scan_results["benchmark_results"] if r is not None]
            if benchmark_results:
                avg_latency = sum(r.latency for r in benchmark_results) / len(benchmark_results)
                avg_download_speed = sum(r.download_speed for r in benchmark_results) / len(benchmark_results)
                
                self.enhanced_stats["performance_metrics"] = {
                    "average_latency": avg_latency,
                    "average_download_speed": avg_download_speed,
                    "total_benchmarked": len(benchmark_results)
                }
    
    def get_enhanced_statistics(self) -> Dict[str, Any]:
        """ç²å–å¢å¼·çµ±è¨ˆä¿¡æ¯"""
        stats = self.enhanced_stats.copy()
        
        # æ·»åŠ åŸºç¤æƒæå™¨çµ±è¨ˆ
        stats["basic_scanner_stats"] = self.basic_scanner.get_scan_stats()
        
        # æ·»åŠ è³ªé‡è©•ä¼°çµ±è¨ˆ
        stats["quality_assessment_stats"] = self.quality_assessor.get_assessment_statistics()
        
        # è¨ˆç®—æˆåŠŸç‡
        if stats["total_discovered"] > 0:
            stats["discovery_to_analysis_rate"] = (stats["total_analyzed"] / stats["total_discovered"]) * 100
        
        if stats["total_analyzed"] > 0:
            stats["high_quality_rate"] = (stats["high_quality_count"] / stats["total_analyzed"]) * 100
        
        return stats
    
    async def export_comprehensive_report(self, scan_results: Dict[str, Any], filename: Optional[str] = None) -> str:
        """å°å‡ºç¶œåˆå ±å‘Š"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"enhanced_proxy_scan_report_{timestamp}.json"
        
        # æº–å‚™å ±å‘Šæ•¸æ“š
        report_data = {
            "report_metadata": {
                "generated_at": datetime.now().isoformat(),
                "scanner_version": "2.0-enhanced",
                "scan_type": "comprehensive"
            },
            "scan_summary": {
                "total_discovered": len(scan_results.get("discovered_proxies", [])),
                "total_analyzed": len(scan_results.get("analyzed_proxies", [])),
                "total_quality_assessed": len(scan_results.get("quality_metrics", [])),
                "geographic_locations": len(set(
                    p.country for p in scan_results.get("analyzed_proxies", []) 
                    if p.country
                ))
            },
            "detailed_results": scan_results,
            "statistics": self.get_enhanced_statistics()
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ“„ ç¶œåˆå ±å‘Šå·²å°å‡º: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"âŒ å°å‡ºç¶œåˆå ±å‘Šå¤±æ•—: {e}")
            raise
    
    async def close(self):
        """é—œé–‰å¢å¼·æƒæå™¨"""
        await self.basic_scanner.close()
        await self.intelligent_detector.close()
        await self.geolocation_detector.close()
        
        logger.info("âœ… å¢å¼·ä»£ç†æƒæå™¨å·²é—œé–‰")