"""Legacy api.py now serves mainly as an aggregator bootstrapping the modular route files.

Most endpoints have been migrated to dedicated route modules:
- routes_proxies.py
- routes_stats.py
- routes_maintenance.py
- routes_health_etl.py
- routes_database.py

Only shared exception handlers and /metrics endpoint remain here.
"""

import asyncio
import logging
from typing import List, Optional, Dict, Any, Union
from datetime import datetime, timedelta
from pathlib import Path

from fastapi import FastAPI, HTTPException, Depends, Query, BackgroundTasks, Request, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel, Field
import redis.asyncio as aioredis
from src.config.settings import settings
import uvicorn
from prometheus_client import Counter, Gauge, Histogram, generate_latest, CONTENT_TYPE_LATEST
from time import perf_counter
from collections import defaultdict, deque

from fastapi import APIRouter
from . import routes_proxies, routes_stats, routes_maintenance, routes_health_etl, routes_database
from .api_shared import (
    require_api_key,
    REQUEST_COUNT,
    REQUEST_LATENCY,
    get_proxy_manager,
    proxy_manager as GLOBAL_PROXY_MANAGER_REF,
)
# å»¶é²å°å…¥ ProxyManager ä»¥é¿å…å¾ªç’°å¼•ç”¨; åƒ…å‹åˆ¥æª¢æŸ¥æ™‚å¼•ç”¨
from typing import TYPE_CHECKING
if TYPE_CHECKING:  # pragma: no cover
    from .manager import ProxyManager

# Create app instance (re-added after refactor)
async def _lifespan(app: FastAPI):
    # Initialize global proxy manager if not already
    from .api_shared import proxy_manager as pm_ref
    # è®€å– git commit hash
    commit_hash = None
    try:
        import subprocess, pathlib
        result = subprocess.run(["git", "rev-parse", "--short", "HEAD"], capture_output=True, text=True, cwd=pathlib.Path(__file__).parent.parent.parent)
        if result.returncode == 0:
            commit_hash = result.stdout.strip()
    except Exception:
        pass
    app.state.commit_hash = commit_hash
    if pm_ref is None:
        from .manager import ProxyManager  # å»¶é²å°å…¥
        mgr = ProxyManager()
        try:
            await mgr.start()
            from . import api_shared
            api_shared.proxy_manager = mgr
            logging.getLogger(__name__).info("âœ… ProxyManager initialized in lifespan")
        except Exception as e:
            logging.getLogger(__name__).error(f"âŒ Failed to start ProxyManager: {e}")
            raise
    yield
    # Shutdown logic
    from .api_shared import proxy_manager as pm_ref_shutdown
    if pm_ref_shutdown:
        try:
            await pm_ref_shutdown.stop()
        except Exception:
            pass

app = FastAPI(title="Proxy Manager API", version="1.0.0", lifespan=_lifespan)

# Mount modular routers
app.include_router(routes_proxies.router)
app.include_router(routes_stats.router)
app.include_router(routes_maintenance.router)
app.include_router(routes_health_etl.router)
app.include_router(routes_database.router)

# ---------------------------------------------------------------------------
# Root & convenience endpoints
# ---------------------------------------------------------------------------
from fastapi.responses import RedirectResponse  # local import (FastAPI already present)

@app.get("/", include_in_schema=False)
async def root_index():
    """Root index: provide quick links instead of 404."""
    return {
        "service": "Proxy Manager API",
        "version": app.version,
    "commit": getattr(app.state, 'commit_hash', None),
        "docs": "/docs",
        "openapi": "/openapi.json",
        "health": "/api/health",
        "metrics": "/metrics",
        "endpoints_prefix": "/api/*",
        "message": "See /docs for interactive API documentation"
    }

@app.get("/health", include_in_schema=False)
async def root_health_redirect():
    """Redirect /health -> /api/health for convenience (browser friendly)."""
    return RedirectResponse(url="/api/health")

@app.get("/api/system/health", summary="ç³»çµ±æ•´é«”ç‹€æ…‹")
async def system_health():
    """å½™ç¸½ ProxyManager (è‹¥å¯ç”¨) èˆ‡åŸºæœ¬æœå‹™ç‹€æ…‹ã€‚"""
    from .api_shared import proxy_manager as pm
    base = {
        "service": "Proxy Manager API",
        "version": app.version,
        "commit": getattr(app.state, 'commit_hash', None),
        "timestamp": datetime.utcnow().isoformat() + 'Z'
    }
    if pm is None:
        base["proxy_manager"] = {"initialized": False}
    else:
        try:
            stats = pm.get_stats()  # type: ignore[attr-defined]
            base["proxy_manager"] = {
                "initialized": True,
                "total_fetched": stats.get('total_fetched'),
                "total_active": stats.get('total_active'),
                "running": stats.get('start_time') is not None,
            }
        except Exception as e:
            base["proxy_manager"] = {"initialized": True, "error": str(e)}
    return base


## Stats & pools endpoints moved to routes_stats / routes_health_etl


@app.post("/api/etl/sync", summary="åŒæ­¥ä»£ç†æ•¸æ“šåˆ° ETL ç³»çµ±", dependencies=[Depends(require_api_key)])
async def sync_to_etl(
    background_tasks: BackgroundTasks,
    pool_types: Optional[str] = Query("hot,warm,cold", description="è¦åŒæ­¥çš„æ± é¡å‹"),
    manager = Depends(get_proxy_manager)
):
    """å°‡ä»£ç†ç®¡ç†å™¨ä¸­çš„æ•¸æ“šåŒæ­¥åˆ° ETL ç³»çµ±"""
    if not ETL_AVAILABLE:
        raise HTTPException(status_code=503, detail="ETL ç³»çµ±ä¸å¯ç”¨")
    
    try:
        # è§£ææ± é¡å‹
        pool_list = []
        if pool_types:
            for pool_name in pool_types.split(','):
                pool_name = pool_name.strip().lower()
                if pool_name in ['hot', 'warm', 'cold']:
                    pool_list.append(pool_name)
        
        if not pool_list:
            pool_list = ['hot', 'warm', 'cold']
        
        # åœ¨èƒŒæ™¯åŸ·è¡ŒåŒæ­¥ä»»å‹™
        background_tasks.add_task(_sync_data_to_etl, manager, pool_list)
        
        return {
            "message": "æ•¸æ“šåŒæ­¥ä»»å‹™å·²å•Ÿå‹•",
            "pool_types": pool_list,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ å•Ÿå‹•æ•¸æ“šåŒæ­¥å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å•Ÿå‹•æ•¸æ“šåŒæ­¥å¤±æ•—: {e}")


## ETL endpoints moved to routes_health_etl


@app.get("/api/metrics/summary", summary="ç²å–ç³»çµ±æŒ‡æ¨™æ‘˜è¦")
async def get_metrics_summary(manager = Depends(get_proxy_manager)):
    """ç²å–ç³»çµ±é—œéµæŒ‡æ¨™çš„æ‘˜è¦ä¿¡æ¯ï¼Œä¾›å‰ç«¯å„€è¡¨æ¿ä½¿ç”¨"""
    try:
        stats = manager.get_stats()
        pool_summary = stats['pool_summary']
        manager_stats = stats['manager_stats']
        
        # è¨ˆç®—æˆåŠŸç‡
        total_requests = manager_stats.get('total_requests', 0)
        successful_requests = manager_stats.get('successful_requests', 0)
        success_rate = (successful_requests / total_requests * 100) if total_requests > 0 else 0
        
        # è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“
        avg_response_time = manager_stats.get('avg_response_time', 0)
        
        # ç²å–å„æ± çš„ä»£ç†æ•¸é‡
        hot_proxies = pool_summary.get('hot_pool_count', 0)
        warm_proxies = pool_summary.get('warm_pool_count', 0)
        cold_proxies = pool_summary.get('cold_pool_count', 0)
        blacklisted_proxies = pool_summary.get('blacklist_count', 0)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "system_health": {
                "status": "healthy" if stats['status']['running'] else "stopped",
                "uptime_seconds": manager_stats.get('uptime_seconds', 0),
                "last_update": manager_stats.get('last_update', datetime.now()).isoformat()
            },
            "proxy_metrics": {
                "total_proxies": pool_summary['total_proxies'],
                "active_proxies": pool_summary['total_active_proxies'],
                "hot_pool": hot_proxies,
                "warm_pool": warm_proxies,
                "cold_pool": cold_proxies,
                "blacklisted": blacklisted_proxies
            },
            "performance_metrics": {
                "success_rate": round(success_rate, 2),
                "avg_response_time_ms": round(avg_response_time * 1000, 2),
                "total_requests": total_requests,
                "successful_requests": successful_requests,
                "failed_requests": total_requests - successful_requests
            },
            "validation_metrics": {
                "total_validations": manager_stats.get('total_validations', 0),
                "successful_validations": manager_stats.get('successful_validations', 0),
                "validation_success_rate": round(
                    (manager_stats.get('successful_validations', 0) / 
                     max(manager_stats.get('total_validations', 1), 1)) * 100, 2
                )
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–æŒ‡æ¨™æ‘˜è¦å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æŒ‡æ¨™æ‘˜è¦å¤±æ•—: {e}")


## Metrics trends moved to routes_stats


## Batch validate moved to routes_maintenance


# éŒ¯èª¤è™•ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    try:
        endpoint = str(request.url.path)
        method = request.method
        status = str(exc.status_code)
        REQUEST_COUNT.labels(endpoint=endpoint, method=method, status=status).inc()
        REQUEST_LATENCY.labels(endpoint=endpoint, method=method, status=status).observe(0)
    except Exception:
        pass
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"âŒ æœªè™•ç†çš„ç•°å¸¸: {exc}")
    try:
        endpoint = str(request.url.path)
        method = request.method
        status = "500"
        REQUEST_COUNT.labels(endpoint=endpoint, method=method, status=status).inc()
        REQUEST_LATENCY.labels(endpoint=endpoint, method=method, status=status).observe(0)
    except Exception:
        pass
    return JSONResponse(
        status_code=500,
        content={
            "error": "å…§éƒ¨æœå‹™å™¨éŒ¯èª¤",
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


# ===== èƒŒæ™¯ä»»å‹™å‡½æ•¸ =====

async def _sync_data_to_etl(manager, pool_types: List[str]):
    """åŒæ­¥æ•¸æ“šåˆ° ETL ç³»çµ±çš„èƒŒæ™¯ä»»å‹™"""
    try:
        logger.info(f"ğŸ”„ é–‹å§‹åŒæ­¥æ•¸æ“šåˆ° ETL ç³»çµ±ï¼Œæ± é¡å‹: {pool_types}")
        
        # ç²å–æ‰€æœ‰ä»£ç†æ•¸æ“š
        all_proxies = []
        for pool_type in pool_types:
            # é€™è£¡æ‡‰è©²æ ¹æ“šå¯¦éš›çš„ ProxyManager API ç²å–ä»£ç†
            # proxies = await manager.get_proxies_from_pool(pool_type)
            # all_proxies.extend(proxies)
            pass
        
        # å°‡æ•¸æ“šç™¼é€åˆ° ETL ç³»çµ±
        # é€™è£¡æ‡‰è©²èª¿ç”¨ ETL API ä¾†è™•ç†æ•¸æ“š
        
        logger.info(f"âœ… æ•¸æ“šåŒæ­¥å®Œæˆï¼Œå…±è™•ç† {len(all_proxies)} å€‹ä»£ç†")
        
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šåŒæ­¥å¤±æ•—: {e}")


## Background tasks relocated or will be reimplemented in dedicated modules


# å•Ÿå‹•æœå‹™å™¨çš„å‡½æ•¸
def start_server(
    host: str = "0.0.0.0",
    port: int = 8000,
    reload: bool = False,
    log_level: str = "info"
):
    """å•Ÿå‹• FastAPI æœå‹™å™¨"""
    uvicorn.run(
        "proxy_manager.api:app",
        host=host,
        port=port,
        reload=reload,
        log_level=log_level,
        access_log=True
    )


@app.get("/metrics", include_in_schema=False)
async def metrics():
    # ä½¿ç”¨ç´”æ–‡æœ¬ Content-Typeï¼Œé¿å…æŸäº›ä»£ç†èª¤è§£æ
    data = generate_latest()
    from fastapi import Response
    return Response(content=data, media_type=CONTENT_TYPE_LATEST)


if __name__ == "__main__":
    # é…ç½®æ—¥èªŒ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # å•Ÿå‹•æœå‹™å™¨
    start_server(reload=True)