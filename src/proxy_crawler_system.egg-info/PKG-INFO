Metadata-Version: 2.4
Name: proxy-crawler-system
Version: 1.0.0
Summary: 專業的代理伺服器爬取與管理系統
Author-email: Jason <jason@example.com>
Project-URL: Homepage, https://github.com/jason/proxy-crawler-system
Project-URL: Repository, https://github.com/jason/proxy-crawler-system.git
Project-URL: Issues, https://github.com/jason/proxy-crawler-system/issues
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.104.0
Requires-Dist: uvicorn[standard]>=0.24.0
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: httpx>=0.24.0
Requires-Dist: requests>=2.31.0
Requires-Dist: beautifulsoup4>=4.12.0
Requires-Dist: lxml>=4.9.0
Requires-Dist: parsel>=1.8.0
Requires-Dist: markdownify>=0.11.6
Requires-Dist: trafilatura>=1.6.0
Requires-Dist: html2text>=2020.1.16
Requires-Dist: readability-lxml>=0.8.1
Requires-Dist: pydantic>=2.0.0
Requires-Dist: dataclasses-json>=0.6.0
Requires-Dist: pandas>=2.1.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: aiofiles>=23.0.0
Requires-Dist: sqlalchemy>=2.0.0
Requires-Dist: psycopg2-binary>=2.9.0
Requires-Dist: redis>=4.6.0
Requires-Dist: aiosqlite>=0.19.0
Requires-Dist: loguru>=0.7.0
Requires-Dist: structlog>=23.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: PyYAML>=6.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: rich>=13.0.0
Requires-Dist: click>=8.1.0
Requires-Dist: typer>=0.9.0
Requires-Dist: chardet>=5.0.0
Requires-Dist: python-dateutil>=2.8.0
Requires-Dist: textstat>=0.7.0
Requires-Dist: Pillow>=10.0.0
Requires-Dist: geopy>=2.4.0
Requires-Dist: geoip2>=4.8.0
Requires-Dist: jinja2>=3.1.6
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.0.280; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"
Provides-Extra: browser-automation
Requires-Dist: playwright>=1.40.0; extra == "browser-automation"
Requires-Dist: selenium>=4.15.0; extra == "browser-automation"
Requires-Dist: undetected-chromedriver>=3.5.5; extra == "browser-automation"
Requires-Dist: webdriver-manager>=4.0.1; extra == "browser-automation"
Provides-Extra: proxy-management
Requires-Dist: PySocks>=1.7.1; extra == "proxy-management"
Requires-Dist: fake-useragent>=1.4.0; extra == "proxy-management"
Provides-Extra: scrapy-framework
Requires-Dist: scrapy>=2.11.0; extra == "scrapy-framework"
Requires-Dist: scrapy-playwright>=0.0.28; extra == "scrapy-framework"
Provides-Extra: monitoring
Requires-Dist: prometheus-client>=0.19.0; extra == "monitoring"
Requires-Dist: tenacity>=8.2.3; extra == "monitoring"
Requires-Dist: retrying>=1.3.4; extra == "monitoring"

# JasonSpider - 代理爬蟲與管理系統

一個功能完整的代理爬蟲與管理系統，支援多來源代理獲取、HTML 轉 Markdown 服務，以及智能代理管理功能。

## 🚀 主要功能

### 1. HTML to Markdown 轉換服務
- 支援多種轉換引擎（markdownify、html2text、pandoc）
- RESTful API 介面
- 批量轉換支援
- 自動檔案儲存與時間戳記

### 2. 代理網站監控
- 多來源代理網站可用性檢查
- 支援 SSL Proxies、Geonode、GitHub 專案等
- 異步並發檢查機制
- 詳細的狀態報告

### 3. 代理管理系統（規劃中）
- 智能代理池管理
- 代理驗證與評分
- 多協議支援（HTTP、SOCKS4、SOCKS5）
- 地理位置分類

## 📁 專案結構

```
JasonSpider/
├── src/                                 # 源代碼目錄
│   ├── html_to_markdown/                # HTML to Markdown 轉換模組
│   └── proxy_manager/                   # 代理管理模組
├── Docs/                                # 專案文檔
├── data/                                # 資料目錄
├── docker/                              # Docker 相關檔案
├── check_proxy_websites.py              # 代理網站檢查工具
└── requirements*.txt                    # 依賴清單
```

## 🛠️ 安裝與使用

### 環境需求
- Python 3.11+
- 推薦使用 `uv` 進行依賴管理

### 快速開始

```bash
# 1. 克隆專案
git clone <repository-url>
cd JasonSpider

# 2. 設置虛擬環境（推薦使用 uv）
uv venv
uv shell

# 3. 安裝依賴
uv sync
# 或使用 pip
pip install -r requirements.txt

# 4. 啟動 HTML to Markdown 服務
python src/main.py
```

### Docker 部署

```bash
# 使用 Docker Compose 啟動所有服務
docker-compose up -d

# 或單獨構建和運行
docker build -t jason-spider .
docker run -p 8000:8000 jason-spider
```

## 📖 API 使用

### HTML to Markdown 轉換

```bash
# 基本轉換
curl -X POST "http://localhost:8000/convert" \
     -H "Content-Type: application/json" \
     -d '{"html": "<h1>Hello World</h1>", "engine": "markdownify"}'

# 批量轉換
curl -X POST "http://localhost:8000/batch-convert" \
     -H "Content-Type: application/json" \
     -d '{"items": [{"html": "<h1>Title 1</h1>"}, {"html": "<h2>Title 2</h2>"}]}'
```

### 代理網站檢查

```bash
# 檢查所有代理網站狀態
python check_proxy_websites.py
```

## 🔧 配置

### 環境變數

複製 `.env.example` 到 `.env` 並根據需要修改配置：

```bash
cp .env.example .env
```

主要配置項目：
- `HOST`: 服務器主機地址（預設：0.0.0.0）
- `PORT`: 服務器端口（預設：8000）
- `LOG_LEVEL`: 日誌級別（預設：INFO）

## 📚 文檔

詳細文檔請參考 `Docs/` 目錄：

- [專案總覽](Docs/PROJECT_OVERVIEW.md) - 完整的專案功能與架構說明
- [架構設計總覽](Docs/架構設計總覽.md) - 系統架構設計文檔
- [ProxyScraper 整合分析](Docs/ProxyScraper整合分析與建議.md) - ProxyScraper 整合方案
- [GitHub 專案分析](Docs/三個GitHub代理專案分析與整合建議.md) - GitHub 代理專案整合建議

## 🤝 貢獻

歡迎提交 Issue 和 Pull Request！

### 開發規範

- 遵循 PEP 8 代碼風格
- 使用 `ruff` 進行代碼格式化和檢查
- 所有函數和類別必須包含中文文檔字符串
- 使用類型提示（Type Hints）

### 提交規範

使用 Conventional Commits 格式：
```
<type>(<scope>): <subject>

例如：
feat(crawler): add free-proxy-list.net crawler module
fix(api): resolve markdown conversion encoding issue
```

## 📄 授權

本專案採用 MIT 授權條款。詳見 [LICENSE](LICENSE) 檔案。

## 🔗 相關連結

- [FastAPI 文檔](https://fastapi.tiangolo.com/)
- [aiohttp 文檔](https://docs.aiohttp.org/)
- [Beautiful Soup 文檔](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

---

**注意**: 本專案仍在積極開發中，部分功能可能尚未完全實現。請參考文檔了解最新進度。
