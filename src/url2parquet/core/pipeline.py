from __future__ import annotations

import hashlib
import time
from pathlib import Path
from typing import Iterable, List

from ..config import PipelineOptions
from ..types import ConvertResult, OutputFile


class Url2ParquetPipeline:
    def __init__(self, options: PipelineOptions):
        self.options = options
        self.work_dir: Path = Path(options.work_dir)
        self.cache_dir: Path = self.work_dir / "cache"
        self.jobs_dir: Path = self.work_dir / "jobs"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.jobs_dir.mkdir(parents=True, exist_ok=True)

    def _checksum(self, url: str) -> str:
        return hashlib.sha256(url.encode("utf-8")).hexdigest()

    def _result_path(self, checksum: str) -> Path:
        return self.cache_dir / checksum / "result.json"

    def _ensure_dir(self, path: Path) -> None:
        path.mkdir(parents=True, exist_ok=True)

    def convert_url(self, url: str) -> ConvertResult:
        start = time.perf_counter()
        checksum = self._checksum(url)
        cache_path = self.cache_dir / checksum
        self._ensure_dir(cache_path)

        # Minimal stub: write markdown and json placeholders, no real fetch/transform (to be implemented)
        md_path = cache_path / "content.md"
        json_path = cache_path / "content.json"
        parquet_path = cache_path / "content.parquet"

        # Create placeholder files if not exist
        if not md_path.exists():
            md_path.write_text(f"# Placeholder for {url}\n\nGenerated by url2parquet stub.", encoding="utf-8")
        if not json_path.exists():
            json_path.write_text('{"url": "%s", "markdown": true}' % url, encoding="utf-8")
        if not parquet_path.exists():
            parquet_path.write_text("PARQUET_PLACEHOLDER", encoding="utf-8")

        files: List[OutputFile] = []
        if "parquet" in self.options.output_formats:
            files.append(OutputFile(format="parquet", path=str(parquet_path)))
        if "json" in self.options.output_formats:
            files.append(OutputFile(format="json", path=str(json_path)))
        if "md" in self.options.output_formats or "markdown" in self.options.output_formats:
            files.append(OutputFile(format="md", path=str(md_path)))

        duration_ms = int((time.perf_counter() - start) * 1000)
        return ConvertResult(
            url=url,
            title=None,
            language=None,
            files=files,
            checksum=f"sha256:{checksum}",
            engine=self.options.extract_mode,
            processing_time_ms=duration_ms,
        )

    def batch_convert(self, urls: Iterable[str]) -> List[ConvertResult]:
        return [self.convert_url(u) for u in urls]


