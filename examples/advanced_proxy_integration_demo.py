#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜ç´šä»£ç†æ•´åˆç¤ºä¾‹

æ­¤ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„é«˜ç´šä»£ç†ç²å–å™¨ã€æƒæå™¨å’Œé…ç½®ç³»çµ±ã€‚
æ¼”ç¤ºäº†ç¬¬ä¸€éšæ®µä»£ç†æ•´åˆçš„æ ¸å¿ƒåŠŸèƒ½ã€‚

ä½œè€…: Jason
æ—¥æœŸ: 2024-01-20
"""

import asyncio
import logging
from pathlib import Path
from typing import List

from src.proxy_manager import (
    ProxyManager,
    ProxyManagerConfig,
    ApiConfig,
    ScannerConfig,
    ProxyNode,
    ProxyFilter,
    ProxyProtocol,
    ProxyAnonymity
)

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def demo_basic_integration():
    """åŸºæœ¬æ•´åˆç¤ºä¾‹"""
    logger.info("ğŸš€ é–‹å§‹åŸºæœ¬ä»£ç†æ•´åˆç¤ºä¾‹")
    
    # å‰µå»ºé…ç½®
    config = ProxyManagerConfig(
        data_dir=Path("data/demo_proxy_manager"),
        
        # API é…ç½®
        api_config=ApiConfig(
            proxyscrape_api_key="your_api_key_here",  # è«‹æ›¿æ›ç‚ºå¯¦éš› API å¯†é‘°
            shodan_api_key="your_shodan_key_here",
            enable_proxyscrape=True,
            enable_github_sources=True,
            enable_shodan=False  # éœ€è¦ä»˜è²» API
        ),
        
        # æƒæå™¨é…ç½®
        scanner_config=ScannerConfig(
            enable_fast_scan=True,
            scan_timeout=5.0,
            max_concurrent_scans=100,
            port_scan_method="connect",  # ä½¿ç”¨é€£æ¥æƒæè€ŒéåŸå§‹å¥—æ¥å­—
            enable_anonymity_detection=True
        ),
        
        # è‡ªå‹•ä»»å‹™
        auto_fetch_enabled=True,
        auto_fetch_interval_hours=2,  # æ›´é »ç¹çš„ç²å–
        auto_cleanup_enabled=True
    )
    
    # å‰µå»ºç®¡ç†å™¨
    manager = ProxyManager(config)
    
    try:
        # å•Ÿå‹•ç®¡ç†å™¨
        await manager.start()
        
        # ç²å–ä»£ç†ï¼ˆåŒ…å«é«˜ç´šä¾†æºï¼‰
        logger.info("ğŸ“¡ é–‹å§‹ç²å–ä»£ç†...")
        proxies = await manager.fetch_proxies()
        
        logger.info(f"âœ… ç²å–åˆ° {len(proxies)} å€‹æœ‰æ•ˆä»£ç†")
        
        # å±•ç¤ºçµ±è¨ˆä¿¡æ¯
        stats = manager.get_stats()
        logger.info(f"ğŸ“Š ç®¡ç†å™¨çµ±è¨ˆ: {stats['manager_stats']}")
        logger.info(f"ğŸŠ ä»£ç†æ± æ‘˜è¦: {stats['pool_summary']}")
        
        # æ¸¬è©¦ä¸åŒé¡å‹çš„ä»£ç†ç²å–
        await demo_proxy_filtering(manager)
        
        # å°å‡ºä»£ç†
        export_path = Path("data/demo_exported_proxies.json")
        exported_count = await manager.export_proxies(export_path)
        logger.info(f"ğŸ“¤ å·²å°å‡º {exported_count} å€‹ä»£ç†åˆ° {export_path}")
        
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹åŸ·è¡Œå¤±æ•—: {e}")
        raise
    finally:
        await manager.stop()
        logger.info("ğŸ›‘ ç®¡ç†å™¨å·²åœæ­¢")


async def demo_proxy_filtering(manager: ProxyManager):
    """ä»£ç†éæ¿¾ç¤ºä¾‹"""
    logger.info("ğŸ” é–‹å§‹ä»£ç†éæ¿¾ç¤ºä¾‹")
    
    # ç²å–é«˜åŒ¿åä»£ç†
    high_anon_filter = ProxyFilter(
        anonymity=[ProxyAnonymity.HIGH_ANONYMOUS],
        min_score=0.7
    )
    
    high_anon_proxies = await manager.get_proxies(
        count=5,
        filter_criteria=high_anon_filter
    )
    
    logger.info(f"ğŸ­ ç²å–åˆ° {len(high_anon_proxies)} å€‹é«˜åŒ¿åä»£ç†")
    for proxy in high_anon_proxies:
        logger.info(f"  - {proxy.url} (åŒ¿ååº¦: {proxy.anonymity.value}, è©•åˆ†: {proxy.score:.2f})")
    
    # ç²å– HTTPS ä»£ç†
    https_filter = ProxyFilter(
        protocols=[ProxyProtocol.HTTPS],
        min_score=0.5
    )
    
    https_proxies = await manager.get_proxies(
        count=3,
        filter_criteria=https_filter
    )
    
    logger.info(f"ğŸ”’ ç²å–åˆ° {len(https_proxies)} å€‹ HTTPS ä»£ç†")
    for proxy in https_proxies:
        logger.info(f"  - {proxy.url} (å”è­°: {proxy.protocol.value})")


async def demo_advanced_features():
    """é«˜ç´šåŠŸèƒ½ç¤ºä¾‹"""
    logger.info("âš¡ é–‹å§‹é«˜ç´šåŠŸèƒ½ç¤ºä¾‹")
    
    # å‰µå»ºé«˜æ€§èƒ½é…ç½®
    config = ProxyManagerConfig(
        data_dir=Path("data/advanced_proxy_manager"),
        
        # å•Ÿç”¨æ‰€æœ‰é«˜ç´šåŠŸèƒ½
        api_config=ApiConfig(
            enable_proxyscrape=True,
            enable_github_sources=True,
            github_update_interval_hours=6,
            proxyscrape_formats=["textplain", "json"]
        ),
        
        # é«˜æ€§èƒ½æƒæé…ç½®
        scanner_config=ScannerConfig(
            enable_fast_scan=True,
            scan_timeout=3.0,
            max_concurrent_scans=200,
            enable_anonymity_detection=True,
            enable_geolocation=True,
            batch_size=50
        ),
        
        # å„ªåŒ–çš„é©—è­‰é…ç½®
        validation_config={
            'timeout': 8,
            'test_urls': [
                'http://httpbin.org/ip',
                'https://api.ipify.org',
                'http://icanhazip.com'
            ],
            'max_retries': 1,
            'verify_anonymity': True
        },
        
        # è‡ªå‹•åŒ–é…ç½®
        auto_fetch_enabled=True,
        auto_fetch_interval_hours=1,
        auto_cleanup_enabled=True,
        auto_cleanup_interval_hours=6
    )
    
    manager = ProxyManager(config)
    
    try:
        await manager.start()
        
        # åŸ·è¡Œå¤šè¼ªç²å–ä»¥æ¸¬è©¦æ€§èƒ½
        for round_num in range(3):
            logger.info(f"ğŸ”„ ç¬¬ {round_num + 1} è¼ªä»£ç†ç²å–")
            
            proxies = await manager.fetch_proxies()
            
            # é©—è­‰ä»£ç†æ± 
            await manager.validate_pools()
            
            # ç²å–è©³ç´°çµ±è¨ˆ
            stats = manager.get_stats()
            logger.info(f"ğŸ“ˆ ç¬¬ {round_num + 1} è¼ªçµ±è¨ˆ:")
            logger.info(f"  - ç¸½ç²å–: {stats['manager_stats']['total_fetched']}")
            logger.info(f"  - ç¸½é©—è­‰: {stats['manager_stats']['total_validated']}")
            logger.info(f"  - ç•¶å‰æ´»èº: {stats['manager_stats']['total_active']}")
            
            # çŸ­æš«ç­‰å¾…
            await asyncio.sleep(2)
        
        # æœ€çµ‚å°å‡º
        final_export = Path("data/final_advanced_proxies.json")
        final_count = await manager.export_proxies(final_export)
        logger.info(f"ğŸ¯ æœ€çµ‚å°å‡º {final_count} å€‹å„ªè³ªä»£ç†")
        
    except Exception as e:
        logger.error(f"âŒ é«˜ç´šåŠŸèƒ½ç¤ºä¾‹å¤±æ•—: {e}")
        raise
    finally:
        await manager.stop()


async def demo_import_export():
    """å°å…¥å°å‡ºç¤ºä¾‹"""
    logger.info("ğŸ’¾ é–‹å§‹å°å…¥å°å‡ºç¤ºä¾‹")
    
    config = ProxyManagerConfig(
        data_dir=Path("data/import_export_demo")
    )
    
    manager = ProxyManager(config)
    
    try:
        await manager.start()
        
        # å‰µå»ºæ¸¬è©¦ä»£ç†åˆ—è¡¨
        test_proxies_file = Path("data/test_proxies.txt")
        test_proxies_file.parent.mkdir(parents=True, exist_ok=True)
        
        # å¯«å…¥æ¸¬è©¦ä»£ç†
        test_proxy_list = [
            "8.8.8.8:8080",
            "1.1.1.1:3128",
            "9.9.9.9:8888"
        ]
        
        with open(test_proxies_file, 'w') as f:
            f.write('\n'.join(test_proxy_list))
        
        logger.info(f"ğŸ“ å‰µå»ºæ¸¬è©¦ä»£ç†æ–‡ä»¶: {test_proxies_file}")
        
        # å°å…¥ä»£ç†
        imported_count = await manager.import_proxies(
            test_proxies_file,
            validate=False  # è·³éé©—è­‰ä»¥åŠ å¿«ç¤ºä¾‹é€Ÿåº¦
        )
        
        logger.info(f"ğŸ“¥ å°å…¥äº† {imported_count} å€‹ä»£ç†")
        
        # å°å‡ºç‚ºä¸åŒæ ¼å¼
        formats = {
            "json": "data/exported_proxies.json",
            "txt": "data/exported_proxies.txt",
            "csv": "data/exported_proxies.csv"
        }
        
        for format_type, file_path in formats.items():
            export_path = Path(file_path)
            export_path.parent.mkdir(parents=True, exist_ok=True)
            
            exported = await manager.export_proxies(export_path, format_type)
            logger.info(f"ğŸ“¤ å°å‡º {exported} å€‹ä»£ç†ç‚º {format_type.upper()} æ ¼å¼: {export_path}")
        
    except Exception as e:
        logger.error(f"âŒ å°å…¥å°å‡ºç¤ºä¾‹å¤±æ•—: {e}")
        raise
    finally:
        await manager.stop()


async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸ¬ é–‹å§‹é«˜ç´šä»£ç†æ•´åˆç¤ºä¾‹")
    
    try:
        # åŸºæœ¬æ•´åˆç¤ºä¾‹
        await demo_basic_integration()
        
        logger.info("\n" + "="*50 + "\n")
        
        # é«˜ç´šåŠŸèƒ½ç¤ºä¾‹
        await demo_advanced_features()
        
        logger.info("\n" + "="*50 + "\n")
        
        # å°å…¥å°å‡ºç¤ºä¾‹
        await demo_import_export()
        
        logger.info("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹åŸ·è¡Œå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹åŸ·è¡Œå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    # ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨
    Path("data").mkdir(exist_ok=True)
    
    # é‹è¡Œç¤ºä¾‹
    asyncio.run(main())