# 代理爬蟲系統架構設計總覽

## 1. 系統概述

本文檔統一定義代理爬蟲系統各模組間的關係、介面規範和資料流向，確保所有子系統協調運作。

## 2. 核心模組架構

```
代理爬蟲系統
├── 爬蟲模組 (Crawler Module)
│   ├── 個別網站爬蟲 ({source_website}__proxy_crawler__.py)
│   ├── 反檢測策略 (Anti-Detection)
│   └── 資料提取引擎 (Data Extraction)
├── 代理管理模組 (Proxy Manager)
│   ├── 代理池管理 (Pool Management)
│   ├── 智能驗證系統 (Validation System)
│   └── 性能監控 (Performance Monitoring)
├── 資料處理模組 (Data Processing)
│   ├── ETL 流程 (Extract, Transform, Load)
│   ├── 資料驗證 (Data Validation)
│   └── 格式化輸出 (Formatted Output)
├── HTML to Markdown 轉換模組 (HTML to Markdown Converter)
│   ├── 多引擎轉換器 (Multi-Engine Converter)
│   ├── 內容清理引擎 (Content Cleaning Engine)
│   └── 智能提取器 (Smart Content Extractor)
└── 配置管理模組 (Configuration)
    ├── 環境設定 (Environment Config)
    ├── 爬蟲參數 (Crawler Parameters)
    └── 驗證規則 (Validation Rules)
```

## 3. 模組間介面定義

### 3.1 爬蟲模組 → 代理管理模組

```python
class CrawlerInterface:
    async def request_proxy(
        self,
        target_url: str,
        protocol: ProxyProtocol = ProxyProtocol.HTTP,
        min_speed: ProxySpeed = ProxySpeed.MEDIUM
    ) -> Optional[ProxyNode]:
        """從代理管理器請求合適的代理"""
        pass
    
    async def report_proxy_result(
        self,
        proxy: ProxyNode,
        success: bool,
        response_time: float
    ) -> None:
        """回報代理使用結果"""
        pass
```

### 3.2 代理管理模組 → 資料處理模組

```python
class ProxyDataInterface:
    async def submit_proxy_data(
        self,
        source: str,
        raw_data: List[Dict[str, Any]]
    ) -> bool:
        """提交原始代理資料進行處理"""
        pass
    
    async def get_processed_data(
        self,
        source: str,
        format_type: str = "markdown"
    ) -> str:
        """獲取處理後的格式化資料"""
        pass
```

### 3.3 HTML to Markdown 轉換模組介面

```python
from enum import Enum
from typing import Optional, Dict, Any

class ConversionMode(Enum):
    """轉換模式枚舉"""
    SIMPLE = "simple"  # 簡單轉換
    CLEAN = "clean"    # 清理轉換
    SMART = "smart"    # 智能提取

class HTMLToMarkdownInterface:
    async def convert_html(
        self,
        html_content: str,
        mode: ConversionMode = ConversionMode.CLEAN,
        options: Optional[Dict[str, Any]] = None
    ) -> str:
        """將 HTML 內容轉換為 Markdown 格式"""
        pass
    
    async def extract_main_content(
        self,
        html_content: str,
        url: Optional[str] = None
    ) -> str:
        """智能提取網頁主要內容並轉換為 Markdown"""
        pass
    
    async def batch_convert(
        self,
        html_list: List[str],
        mode: ConversionMode = ConversionMode.CLEAN
    ) -> List[str]:
        """批量轉換 HTML 內容"""
        pass
```

## 4. 資料流向圖

```
[網站資料源] 
    ↓ (爬取)
[個別爬蟲] 
    ↓ (原始 HTML 資料)
[HTML to Markdown 轉換模組] 
    ↓ (清理轉換)
[資料處理模組] 
    ↓ (清理/驗證)
[代理管理模組] 
    ↓ (分類/評分)
[代理池] 
    ↓ (提供服務)
[爬蟲請求] 
    ↓ (性能回報)
[監控系統]
```

### 4.1 HTML to Markdown 轉換流程

```
[原始 HTML] 
    ↓ (內容提取)
[智能提取器] 
    ↓ (清理處理)
[內容清理引擎] 
    ↓ (格式轉換)
[多引擎轉換器] 
    ↓ (輸出)
[乾淨的 Markdown]
```

## 5. 統一配置規範

### 5.1 檔案命名標準

- **爬蟲檔案**: `{source_website}__proxy_crawler__.py`
- **輸出檔案**: `{source_website}_{timestamp}_proxies.md`
- **配置檔案**: `{module_name}_config.yaml`
- **時間戳格式**: `YYYYMMDD_HHMMSS`

### 5.2 資料模型統一

```python
@dataclass
class ProxyNode:
    """統一的代理節點資料模型"""
    host: str
    port: int
    protocol: ProxyProtocol
    anonymity: ProxyAnonymity
    country: Optional[str] = None
    response_time: float = 0.0
    success_rate: float = 0.0
    source: str = "unknown"
```

## 6. 技術棧整合

### 6.1 核心技術棧

- **語言**: Python 3.11+
- **異步框架**: `asyncio` + `aiohttp`
- **資料驗證**: `pydantic`
- **HTML 解析**: `lxml` (生產環境) / `beautifulsoup4` (開發測試)
- **瀏覽器自動化**: `playwright` (首選) / `selenium`
- **日誌記錄**: `loguru`
- **HTML to Markdown 轉換**: `markdownify` (首選) / `html2text` / `trafilatura` (生產環境推薦)

### 6.2 反檢測技術整合

- **User-Agent 輪換**: 整合進階技術報告中的 `UAManager`
- **代理驗證**: 使用完美 Proxy Manager 的 `ProxyValidator`
- **TLS 指紋**: 配合 `curl_cffi` 或 `tls-client`

## 7. 部署與維護

### 7.1 環境管理

```bash
# 虛擬環境設置
uv venv
uv shell

# 依賴安裝
uv add aiohttp pydantic lxml loguru playwright
```

### 7.2 監控指標

- **爬蟲性能**: 成功率、響應時間、資料品質
- **代理品質**: 可用性、速度、匿名性
- **系統資源**: CPU、記憶體、網路頻寬

## 8. 開發規範

### 8.1 程式碼品質

- 遵循 **PEP 8** 風格指南
- 使用 `ruff format` 進行格式化
- 強制類型提示 (Type Hints)
- Google 風格中文文檔字符串

### 8.2 版本控制

- 使用 **Conventional Commits** 規範
- 功能分支開發策略
- 自動化測試與部署

---

**注意**: 本文檔為系統架構的統一規範，所有子模組的開發都應遵循此架構設計。如有衝突，以本文檔為準。