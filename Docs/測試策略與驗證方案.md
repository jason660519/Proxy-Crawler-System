# JasonSpider 測試策略與驗證方案

**制定時間**: 2025-01-07  
**適用範圍**: 代理抓取、ETL 流程、系統整合測試  
**測試目標**: 驗證系統功能完整性、數據品質、ETL 規範遵守

---

## 🎯 測試目標

### 主要目標

1. **驗證代理抓取功能**: 確認系統能成功從多個來源獲取代理
2. **檢查文件生成**: 驗證 ETL 流程能正確生成各種格式的輸出文件
3. **遵守 ETL 規範**: 確保數據處理流程符合設計規範
4. **系統整合測試**: 驗證各模組間協同工作正常

### 成功標準

- 代理抓取成功率 ≥ 70%
- 文件生成完整性 100%
- ETL 流程各階段正常執行
- 系統穩定運行 ≥ 30 分鐘

---

## 📋 測試計劃

### 階段 1: 基礎功能測試 (30 分鐘)

#### 1.1 系統啟動測試

```bash
# 測試 Docker 服務啟動
docker-compose up -d

# 驗證服務健康狀態
curl http://localhost:8000/health
curl http://localhost:8001/health

# 檢查資料庫連接
docker-compose exec postgres_db pg_isready -U proxyadmin
```

#### 1.2 配置驗證測試

```python
# 測試配置加載
python -c "
from src.proxy_manager.config import get_config
config = get_config()
print('配置加載成功:', config)
"

# 測試環境變數
python -c "
import os
print('DB_USER:', os.getenv('DB_USER'))
print('DB_PASSWORD:', os.getenv('DB_PASSWORD'))
print('DB_NAME:', os.getenv('DB_NAME'))
"
```

### 階段 2: 代理抓取測試 (45 分鐘)

#### 2.1 單一來源測試

```python
# 測試 SSL Proxies 抓取
python -c "
import asyncio
from src.proxy_manager.fetchers import SSLProxiesFetcher

async def test_ssl_proxies():
    fetcher = SSLProxiesFetcher()
    proxies = await fetcher.fetch_proxies(limit=10)
    print(f'SSL Proxies 抓取成功: {len(proxies)} 個代理')
    for proxy in proxies[:3]:
        print(f'  - {proxy.host}:{proxy.port} ({proxy.protocol})')

asyncio.run(test_ssl_proxies())
"
```

#### 2.2 多來源整合測試

```python
# 測試所有來源抓取
python -c "
import asyncio
from src.proxy_manager.manager import ProxyManager

async def test_all_sources():
    manager = ProxyManager()
    await manager.start()

    # 測試基本抓取
    proxies = await manager.fetch_proxies()
    print(f'總共抓取: {len(proxies)} 個代理')

    # 按來源統計
    sources = {}
    for proxy in proxies:
        source = getattr(proxy, 'source', 'unknown')
        sources[source] = sources.get(source, 0) + 1

    print('按來源統計:')
    for source, count in sources.items():
        print(f'  {source}: {count} 個')

    await manager.stop()

asyncio.run(test_all_sources())
"
```

#### 2.3 高級獲取器測試

```python
# 測試高級獲取器
python -c "
import asyncio
from src.proxy_manager.advanced_fetchers import AdvancedProxyFetcherManager

async def test_advanced_fetchers():
    config = {
        'proxyscrape_api_key': None,  # 如果有 API 金鑰
        'github_token': None,
        'shodan_api_key': None
    }

    manager = AdvancedProxyFetcherManager(config)

    # 測試 GitHub 來源
    github_proxies = await manager.fetch_github_proxies()
    print(f'GitHub 代理: {len(github_proxies)} 個')

    # 測試 ProxyScrape
    proxyscrape_proxies = await manager.fetch_proxyscrape_proxies()
    print(f'ProxyScrape 代理: {len(proxyscrape_proxies)} 個')

asyncio.run(test_advanced_fetchers())
"
```

### 階段 3: ETL 流程測試 (60 分鐘)

#### 3.1 數據提取測試

```python
# 測試 ETL 數據提取
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_extract():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # 測試提取階段
    result = await pipeline.extract_proxies()
    print(f'ETL 提取完成: {result.total_records} 個記錄')
    print(f'成功: {result.successful_records}, 失敗: {result.failed_records}')
    print(f'成功率: {result.success_rate:.2%}')

asyncio.run(test_etl_extract())
"
```

#### 3.2 數據轉換測試

```python
# 測試數據轉換
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_transform():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # 先提取數據
    extract_result = await pipeline.extract_proxies()

    # 測試轉換階段
    transform_result = await pipeline.transform_proxies(extract_result.data)
    print(f'ETL 轉換完成: {transform_result.total_records} 個記錄')
    print(f'成功: {transform_result.successful_records}, 失敗: {transform_result.failed_records}')
    print(f'成功率: {transform_result.success_rate:.2%}')

asyncio.run(test_etl_transform())
"
```

#### 3.3 數據驗證測試

```python
# 測試數據驗證
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_validate():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # 先提取和轉換數據
    extract_result = await pipeline.extract_proxies()
    transform_result = await pipeline.transform_proxies(extract_result.data)

    # 測試驗證階段
    validate_result = await pipeline.validate_proxies(transform_result.data)
    print(f'ETL 驗證完成: {validate_result.total_records} 個記錄')
    print(f'成功: {validate_result.successful_records}, 失敗: {validate_result.failed_records}')
    print(f'成功率: {validate_result.success_rate:.2%}')

asyncio.run(test_etl_validate())
"
```

#### 3.4 數據加載測試

```python
# 測試數據加載
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_load():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # 執行完整 ETL 流程
    result = await pipeline.run_full_etl()
    print(f'ETL 完整流程完成: {result.total_records} 個記錄')
    print(f'成功: {result.successful_records}, 失敗: {result.failed_records}')
    print(f'成功率: {result.success_rate:.2%}')

asyncio.run(test_etl_load())
"
```

### 階段 4: 文件生成驗證 (30 分鐘)

#### 4.1 檢查輸出文件

```bash
# 檢查 ETL 輸出文件
ls -la data/raw/
ls -la data/processed/
ls -la data/validated/
ls -la data/reports/

# 檢查文件內容
echo "=== Raw 數據 ==="
head -20 data/raw/proxies_raw_*.json

echo "=== Processed 數據 ==="
head -20 data/processed/proxies_processed_*.json

echo "=== Validated 數據 ==="
head -20 data/validated/proxies_validated_*.json

echo "=== 報告文件 ==="
head -20 data/reports/proxy_etl_report_*.md
```

#### 4.2 驗證文件格式

```python
# 驗證 JSON 文件格式
python -c "
import json
from pathlib import Path

def validate_json_files():
    data_dir = Path('data')

    # 檢查 raw 文件
    raw_files = list(data_dir.glob('raw/*.json'))
    print(f'Raw JSON 文件: {len(raw_files)} 個')
    for file in raw_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f'  ✅ {file.name}: {len(data.get("proxies", []))} 個代理')
        except Exception as e:
            print(f'  ❌ {file.name}: 格式錯誤 - {e}')

    # 檢查 processed 文件
    processed_files = list(data_dir.glob('processed/*.json'))
    print(f'Processed JSON 文件: {len(processed_files)} 個')
    for file in processed_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f'  ✅ {file.name}: {len(data.get("proxies", []))} 個代理')
        except Exception as e:
            print(f'  ❌ {file.name}: 格式錯誤 - {e}')

validate_json_files()
"
```

### 階段 5: 系統整合測試 (45 分鐘)

#### 5.1 API 端點測試

```bash
# 測試主要 API 端點
echo "=== 系統狀態 ==="
curl -s http://localhost:8000/ | jq .

echo "=== 健康檢查 ==="
curl -s http://localhost:8000/health | jq .

echo "=== 代理統計 ==="
curl -s http://localhost:8000/api/stats | jq .

echo "=== 代理列表 ==="
curl -s "http://localhost:8000/api/proxies?limit=5" | jq .
```

#### 5.2 代理池管理測試

```python
# 測試代理池管理
python -c "
import asyncio
from src.proxy_manager.manager import ProxyManager

async def test_pool_management():
    manager = ProxyManager()
    await manager.start()

    # 獲取代理統計
    stats = await manager.get_statistics()
    print('代理池統計:')
    print(f'  總代理數: {stats.get("total_proxies", 0)}')
    print(f'  熱池: {stats.get("hot_pool", 0)}')
    print(f'  溫池: {stats.get("warm_pool", 0)}')
    print(f'  冷池: {stats.get("cold_pool", 0)}')
    print(f'  黑名單: {stats.get("blacklist", 0)}')

    # 測試代理獲取
    proxies = await manager.get_proxies(limit=10)
    print(f'獲取代理: {len(proxies)} 個')

    await manager.stop()

asyncio.run(test_pool_management())
"
```

#### 5.3 資料庫連接測試

```python
# 測試資料庫連接
python -c "
import asyncio
import asyncpg

async def test_database_connection():
    try:
        # 測試 PostgreSQL 連接
        conn = await asyncpg.connect(
            host='localhost',
            port=5432,
            user='proxyadmin',
            password='proxyadmin123',
            database='proxypool'
        )

        # 測試查詢
        result = await conn.fetchval('SELECT version()')
        print(f'✅ PostgreSQL 連接成功: {result}')

        await conn.close()

    except Exception as e:
        print(f'❌ PostgreSQL 連接失敗: {e}')

asyncio.run(test_database_connection())
"
```

### 階段 6: 性能壓力測試 (30 分鐘)

#### 6.1 並發測試

```python
# 測試並發處理能力
python -c "
import asyncio
import time
from src.proxy_manager.manager import ProxyManager

async def test_concurrent_processing():
    manager = ProxyManager()
    await manager.start()

    # 測試並發代理獲取
    start_time = time.time()

    tasks = []
    for i in range(5):  # 5 個並發任務
        task = manager.fetch_proxies()
        tasks.append(task)

    results = await asyncio.gather(*tasks)
    end_time = time.time()

    total_proxies = sum(len(result) for result in results)
    print(f'並發測試完成: {total_proxies} 個代理')
    print(f'處理時間: {end_time - start_time:.2f} 秒')
    print(f'平均速度: {total_proxies / (end_time - start_time):.2f} 代理/秒')

    await manager.stop()

asyncio.run(test_concurrent_processing())
"
```

#### 6.2 內存使用測試

```python
# 測試內存使用
python -c "
import psutil
import os
import time
from src.proxy_manager.manager import ProxyManager

async def test_memory_usage():
    process = psutil.Process(os.getpid())

    # 記錄初始內存
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'初始內存使用: {initial_memory:.2f} MB')

    manager = ProxyManager()
    await manager.start()

    # 記錄啟動後內存
    startup_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'啟動後內存使用: {startup_memory:.2f} MB')

    # 執行代理獲取
    proxies = await manager.fetch_proxies()

    # 記錄獲取後內存
    after_fetch_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'獲取後內存使用: {after_fetch_memory:.2f} MB')
    print(f'內存增長: {after_fetch_memory - startup_memory:.2f} MB')

    await manager.stop()

asyncio.run(test_memory_usage())
"
```

---

## 📊 測試結果評估

### 評估標準

#### 功能完整性 (40%)

- 代理抓取成功率 ≥ 70%
- 文件生成完整性 100%
- ETL 流程各階段正常執行
- API 端點可用性 100%

#### 數據品質 (30%)

- 代理驗證準確性 ≥ 80%
- 數據格式正確性 100%
- 重複數據率 ≤ 5%
- 地理位置信息完整性 ≥ 60%

#### 系統性能 (20%)

- 響應時間 ≤ 2 秒
- 內存使用 ≤ 1GB
- 並發處理能力 ≥ 50 個請求/秒
- 系統穩定性 ≥ 30 分鐘

#### 錯誤處理 (10%)

- 異常捕獲率 100%
- 錯誤恢復能力 ≥ 90%
- 日誌記錄完整性 100%
- 監控告警及時性 100%

### 測試報告模板

```markdown
# 測試報告

## 測試概況

- 測試時間: 2025-01-07
- 測試環境: Docker 容器
- 測試範圍: 完整系統功能

## 測試結果

### 功能測試

- ✅ 代理抓取: 成功 (85% 成功率)
- ✅ 文件生成: 成功 (100% 完整性)
- ✅ ETL 流程: 成功 (90% 成功率)
- ✅ API 服務: 成功 (100% 可用性)

### 性能測試

- ✅ 響應時間: 1.2 秒 (目標 ≤ 2 秒)
- ✅ 內存使用: 512MB (目標 ≤ 1GB)
- ✅ 並發處理: 75 請求/秒 (目標 ≥ 50)
- ✅ 系統穩定性: 45 分鐘 (目標 ≥ 30 分鐘)

### 數據品質

- ✅ 代理驗證: 82% 準確性 (目標 ≥ 80%)
- ✅ 數據格式: 100% 正確性
- ✅ 重複數據: 3% (目標 ≤ 5%)
- ✅ 地理位置: 65% 完整性 (目標 ≥ 60%)

## 問題與建議

1. 代理驗證準確性需要提升
2. 地理位置信息需要補充
3. 內存使用可以進一步優化

## 總體評估

系統功能基本完整，性能表現良好，建議進行優化後正式部署。
```

---

## 🚀 執行建議

### 立即執行

1. **啟動測試環境**: 確保 Docker 服務正常運行
2. **執行基礎測試**: 驗證系統啟動和配置
3. **進行功能測試**: 測試代理抓取和 ETL 流程

### 持續監控

1. **性能監控**: 監控系統資源使用情況
2. **錯誤追蹤**: 記錄和分析錯誤日誌
3. **數據品質**: 定期檢查數據品質指標

### 優化改進

1. **性能優化**: 根據測試結果調整參數
2. **功能完善**: 修復發現的問題
3. **文檔更新**: 更新測試文檔和操作指南

---

**測試策略制定完成**  
**建議執行時間**: 3-4 小時  
**預期成功率**: 85% 以上

