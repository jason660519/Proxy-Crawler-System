# å®Œç¾ Proxy Manager è¨­è¨ˆæ–¹æ¡ˆ

## ç³»çµ±æ¶æ§‹è¨­è¨ˆ

ä¸‹åœ–å±•ç¤ºä»£ç†ç®¡ç†ç³»çµ±çš„æ ¸å¿ƒçµ„æˆèˆ‡è³‡æ–™æµï¼š

```mermaid
graph TB
    subgraph æ•¸æ“šä¾†æºå±¤
        S1[å…è²»ä»£ç†æº]
        S2[ä»˜è²»ä»£ç† API]
        S3[è‡ªå»ºä»£ç†æ± ]
        S4[é›²æœå‹™å•† API]
    end

    subgraph æ ¸å¿ƒç®¡ç†å±¤
        M1[ä»£ç†ç²å–æ¨¡çµ„]
        M2[è³ªé‡é©—è­‰æ¨¡çµ„]
        M3[æ™ºèƒ½åˆ†é…æ¨¡çµ„]
        M4[æ€§èƒ½ç›£æ§æ¨¡çµ„]
    end

    subgraph å­˜å„²å±¤
        DB1[(ç†±ä»£ç†æ± \né«˜æ€§èƒ½)]
        DB2[(æº«ä»£ç†æ± \nä¸­ç­‰æ€§èƒ½)]
        DB3[(å†·ä»£ç†æ± \nä½æ€§èƒ½)]
        DB4[(é»‘åå–®æ± \nå¤±æ•ˆä»£ç†)]
    end

    subgraph æœå‹™å±¤
        API1[REST API]
        API2[å¯¦æ™‚çµ±è¨ˆé¢æ¿]
        API3[é…ç½®ç®¡ç†]
    end

    subgraph æ¶ˆè²»å±¤
        C1[çˆ¬èŸ²æœå‹™]
        C2[æ•¸æ“šæ¡é›†]
        C3[API å®¢æˆ¶ç«¯]
    end

    S1 --> M1
    S2 --> M1
    S3 --> M1
    S4 --> M1
    M1 --> M2
    M2 --> DB1
    M2 --> DB2
    M2 --> DB3
    M2 --> DB4
    DB1 --> M3
    DB2 --> M3
    DB3 --> M3
    M3 --> API1
    M4 --> API2
    API1 --> C1
    API1 --> C2
    API1 --> C3
```

## 1. æ ¸å¿ƒé¡è¨­è¨ˆ

### 1.1 ä»£ç†æ•¸æ“šæ¨¡å‹

```python
from dataclasses import dataclass
from enum import Enum
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
import asyncio


class ProxyProtocol(Enum):
    HTTP = "http"
    HTTPS = "https"
    SOCKS4 = "socks4"
    SOCKS5 = "socks5"


class ProxyAnonymity(Enum):
    TRANSPARENT = "transparent"
    ANONYMOUS = "anonymous"
    ELITE = "elite"


class ProxySpeed(Enum):
    VERY_FAST = "very_fast"    # <100ms
    FAST = "fast"              # 100-300ms
    MEDIUM = "medium"          # 300-800ms
    SLOW = "slow"              # 800-2000ms
    VERY_SLOW = "very_slow"    # >2000ms


@dataclass
class ProxyNode:
    id: str
    host: str
    port: int
    protocol: ProxyProtocol
    anonymity: ProxyAnonymity
    username: Optional[str] = None
    password: Optional[str] = None

    # æ€§èƒ½æŒ‡æ¨™
    response_time: float = 0.0
    success_rate: float = 0.0
    speed: ProxySpeed = ProxySpeed.MEDIUM
    last_checked: datetime = datetime.now()
    last_used: datetime = datetime.now()

    # å…ƒæ•¸æ“š
    country: Optional[str] = None
    city: Optional[str] = None
    isp: Optional[str] = None
    source: str = "unknown"

    # ä½¿ç”¨çµ±è¨ˆ
    total_requests: int = 0
    failed_requests: int = 0
    success_requests: int = 0
    bandwidth_used: float = 0.0  # MB

    @property
    def url(self) -> str:
        if self.username and self.password:
            return f"{self.protocol.value}://{self.username}:{self.password}@{self.host}:{self.port}"
        return f"{self.protocol.value}://{self.host}:{self.port}"

    @property
    def is_available(self) -> bool:
        return (datetime.now() - self.last_checked) < timedelta(minutes=5)

    @property
    def score(self) -> float:
        """ç¶œåˆè©•åˆ†ç®—æ³•"""
        time_score = 1.0 / max(0.1, self.response_time)
        success_score = self.success_rate
        freshness = 1.0 if self.is_available else 0.5
        return (time_score * 0.4 + success_score * 0.4 + freshness * 0.2) * 100
```

### 1.2 ä»£ç†ç®¡ç†å™¨æ ¸å¿ƒ

```python
class PerfectProxyManager:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.proxy_pools = {
            'hot': [],      # é«˜æ€§èƒ½ä»£ç†
            'warm': [],     # ä¸­ç­‰æ€§èƒ½ä»£ç†
            'cold': [],     # ä½æ€§èƒ½ä»£ç†
            'blacklist': [] # å¤±æ•ˆä»£ç†
        }
        self.performance_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'avg_response_time': 0.0,
            'total_bandwidth': 0.0
        }
        self._lock = asyncio.Lock()
        self._initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨"""
        if self._initialized:
            return
        await self._load_config()
        asyncio.create_task(self._background_validator())
        asyncio.create_task(self._background_scraper())
        asyncio.create_task(self._performance_monitor())
        await self._refresh_proxies()
        self._initialized = True
        print("âœ… Proxy Manager åˆå§‹åŒ–å®Œæˆ")

    async def get_proxy(self,
                        target_url: Optional[str] = None,
                        protocol: Optional[ProxyProtocol] = None,
                        min_speed: ProxySpeed = ProxySpeed.MEDIUM,
                        country: Optional[str] = None,
                        anonymity: ProxyAnonymity = ProxyAnonymity.ANONYMOUS) -> Optional[ProxyNode]:
        """æ™ºèƒ½ç²å–æœ€åˆé©çš„ä»£ç†"""
        async with self._lock:
            candidates: list[ProxyNode] = []
            for pool_name in ['hot', 'warm', 'cold']:
                for proxy in self.proxy_pools[pool_name]:
                    if self._matches_criteria(proxy, target_url, protocol, min_speed, country, anonymity):
                        candidates.append(proxy)
            if not candidates:
                return None
            candidates.sort(key=lambda x: x.score, reverse=True)
            selected_proxy = candidates[0]
            selected_proxy.last_used = datetime.now()
            selected_proxy.total_requests += 1
            return selected_proxy

    async def report_proxy_performance(self,
                                       proxy: ProxyNode,
                                       success: bool,
                                       response_time: float,
                                       bandwidth_used: float = 0.0):
        """å ±å‘Šä»£ç†ä½¿ç”¨æ€§èƒ½"""
        async with self._lock:
            proxy.response_time = (proxy.response_time * 0.8 + response_time * 0.2)
            proxy.bandwidth_used += bandwidth_used
            if success:
                proxy.success_requests += 1
                proxy.success_rate = proxy.success_requests / proxy.total_requests
                self.performance_stats['successful_requests'] += 1
            else:
                proxy.failed_requests += 1
                self.performance_stats['failed_requests'] += 1
                if proxy.failed_requests > 10 and proxy.success_rate < 0.3:
                    await self._blacklist_proxy(proxy)
            self.performance_stats['total_requests'] += 1
            self.performance_stats['avg_response_time'] = (
                self.performance_stats['avg_response_time'] * 0.9 + response_time * 0.1
            )
            self.performance_stats['total_bandwidth'] += bandwidth_used
            await self._reclassify_proxy(proxy)
```

## 2. æ™ºèƒ½é©—è­‰ç³»çµ±

### 2.0 é©—è­‰ç­–ç•¥æ•´åˆèªªæ˜

æœ¬é©—è­‰ç³»çµ±æ•´åˆäº†ã€Œç¶²è·¯çˆ¬èŸ²é€²éšæŠ€è¡“èˆ‡åæª¢æ¸¬ç­–ç•¥å ±å‘Šã€ä¸­çš„åæª¢æ¸¬æŠ€è¡“ï¼Œå½¢æˆçµ±ä¸€çš„ä»£ç†é©—è­‰æ¡†æ¶ï¼š

- **æ ¸å¿ƒé©—è­‰å¼•æ“**ï¼šä½¿ç”¨æœ¬æ–‡æª”å®šç¾©çš„ `ProxyValidator` é¡
- **åæª¢æ¸¬ç­–ç•¥**ï¼šæ•´åˆé€²éšæŠ€è¡“å ±å‘Šä¸­çš„ User-Agent è¼ªæ›ã€TLS æŒ‡ç´‹æ¨¡æ“¬ç­‰æŠ€è¡“
- **çµ±ä¸€ä»‹é¢**ï¼šæ‰€æœ‰é©—è­‰åŠŸèƒ½é€šé `PerfectProxyManager` çµ±ä¸€èª¿ç”¨

### 2.1 å¤šç¶­åº¦é©—è­‰ç­–ç•¥

```python
class ProxyValidator:
    def __init__(self, manager: PerfectProxyManager):
        self.manager = manager
        self.test_urls = [
            'http://httpbin.org/ip',
            'http://httpbin.org/user-agent',
            'https://www.google.com',
            'https://www.amazon.com',
            'https://httpbin.org/headers'
        ]
        self.validation_metrics = {
            'connectivity': 0.3,
            'speed': 0.25,
            'anonymity': 0.2,
            'stability': 0.15,
            'compatibility': 0.1
        }

    async def validate_proxy(self, proxy: ProxyNode) -> Dict[str, Any]:
        """å…¨é¢é©—è­‰ä»£ç†æ€§èƒ½"""
        results = {
            'connectivity': await self._test_connectivity(proxy),
            'speed': await self._test_speed(proxy),
            'anonymity': await self._test_anonymity(proxy),
            'stability': await self._test_stability(proxy),
            'compatibility': await self._test_compatibility(proxy)
        }
        total_score = 0.0
        for metric, weight in self.validation_metrics.items():
            total_score += results[metric]['score'] * weight
        results['overall_score'] = total_score
        results['is_valid'] = total_score >= 0.6
        return results

    async def _test_connectivity(self, proxy: ProxyNode) -> Dict[str, Any]:
        success_count = 0
        total_tests = len(self.test_urls)
        response_times: list[float] = []
        for url in self.test_urls:
            try:
                start_time = asyncio.get_event_loop().time()
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, proxy=proxy.url, timeout=10) as response:
                        if response.status == 200:
                            success_count += 1
                            response_time = asyncio.get_event_loop().time() - start_time
                            response_times.append(response_time)
            except Exception:
                continue
        connectivity_rate = success_count / total_tests
        avg_response_time = sum(response_times) / len(response_times) if response_times else 10.0
        return {
            'success_rate': connectivity_rate,
            'avg_response_time': avg_response_time,
            'score': min(1.0, connectivity_rate * 0.7 + (1.0 / max(0.1, avg_response_time)) * 0.3)
        }

    async def _test_anonymity(self, proxy: ProxyNode) -> Dict[str, Any]:
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('https://httpbin.org/ip', proxy=proxy.url) as response:
                    data = await response.json()
                    origin_ip = data.get('origin', '')
                async with session.get('https://httpbin.org/headers', proxy=proxy.url) as response:
                    headers_data = await response.json()
                    headers = headers_data.get('headers', {})
                reveals_real_ip = self.manager.config.get('real_ip') in origin_ip
                has_proxy_headers = any('proxy' in key.lower() for key in headers.keys())
                if reveals_real_ip:
                    anonymity_level = ProxyAnonymity.TRANSPARENT
                    score = 0.2
                elif has_proxy_headers:
                    anonymity_level = ProxyAnonymity.ANONYMOUS
                    score = 0.6
                else:
                    anonymity_level = ProxyAnonymity.ELITE
                    score = 1.0
                proxy.anonymity = anonymity_level
                return {'level': anonymity_level, 'score': score}
        except Exception:
            return {'level': ProxyAnonymity.TRANSPARENT, 'score': 0.0}
```

## 3. è³‡æºèª¿åº¦ç³»çµ±

### 3.1 æ™ºèƒ½è³‡æºåˆ†é…

```python
class ResourceScheduler:
    def __init__(self, manager: PerfectProxyManager):
        self.manager = manager
        self.usage_patterns: Dict[str, Any] = {}
        self.proxy_allocations: Dict[str, Any] = {}

    async def allocate_proxies(self, client_id: str, requirements: Dict[str, Any]) -> List[ProxyNode]:
        required_count = requirements.get('count', 1)
        min_speed = requirements.get('min_speed', ProxySpeed.MEDIUM)
        target_url = requirements.get('target_url')
        allocated_proxies: list[ProxyNode] = []
        async with self.manager._lock:
            for pool_name in ['hot', 'warm', 'cold']:
                if len(allocated_proxies) >= required_count:
                    break
                available_proxies = [
                    p for p in self.manager.proxy_pools[pool_name]
                    if self._matches_requirements(p, requirements)
                ]
                available_proxies.sort(key=lambda x: x.score, reverse=True)
                allocated_proxies.extend(available_proxies[:required_count - len(allocated_proxies)])
        self.proxy_allocations[client_id] = {
            'proxies': allocated_proxies,
            'allocated_at': datetime.now(),
            'requirements': requirements
        }
        return allocated_proxies

    async def optimize_allocation(self):
        usage_analysis = self._analyze_usage_patterns()
        hot_pool_target = max(20, int(usage_analysis['high_demand'] * 50))
        warm_pool_target = max(30, int(usage_analysis['medium_demand'] * 70))
        await self._resize_pools(hot_pool_target, warm_pool_target)

    def _analyze_usage_patterns(self) -> Dict[str, float]:
        return {
            'high_demand': 0.6,
            'medium_demand': 0.3,
            'low_demand': 0.1,
            'peak_hours': [9, 10, 11, 14, 15, 16],
            'off_peak_hours': [0, 1, 2, 3, 4, 5]
        }
```

## 4. ç›£æ§èˆ‡å‘Šè­¦ç³»çµ±

### 4.1 å¯¦æ™‚æ€§èƒ½ç›£æ§

```python
class MonitoringSystem:
    def __init__(self, manager: PerfectProxyManager):
        self.manager = manager
        self.metrics_history = {
            'success_rate': [],
            'response_time': [],
            'proxy_count': [],
            'bandwidth_usage': []
        }

    async def start_monitoring(self):
        while True:
            await asyncio.sleep(60)  # æ¯åˆ†é˜æ”¶é›†ä¸€æ¬¡æŒ‡æ¨™
            stats = {
                'timestamp': datetime.now(),
                'success_rate': self.manager.performance_stats['successful_requests'] /
                               max(1, self.manager.performance_stats['total_requests']),
                'avg_response_time': self.manager.performance_stats['avg_response_time'],
                'total_proxies': sum(len(pool) for pool in self.manager.proxy_pools.values()),
                'bandwidth_usage': self.manager.performance_stats['total_bandwidth']
            }
            for key in self.metrics_history:
                self.metrics_history[key].append(stats[key])
            await self._check_alerts(stats)

    async def _check_alerts(self, stats: Dict[str, Any]):
        if stats['success_rate'] < 0.5:
            await self._trigger_alert('low_success_rate', f"æˆåŠŸç‡éä½: {stats['success_rate']:.2%}")
        if stats['avg_response_time'] > 5.0:
            await self._trigger_alert('high_response_time', f"éŸ¿æ‡‰æ™‚é–“éé«˜: {stats['avg_response_time']:.2f}s")
        if stats['total_proxies'] < 10:
            await self._trigger_alert('low_proxy_count', f"å¯ç”¨ä»£ç†éå°‘: {stats['total_proxies']}")

    async def _trigger_alert(self, alert_type: str, message: str):
        print(f"ğŸš¨ ALERT [{alert_type}]: {message}")
```

## 5. é…ç½®èˆ‡éƒ¨ç½²æ–¹æ¡ˆ

### 5.1 Docker éƒ¨ç½²é…ç½®

```yaml
# docker-compose.yml
version: '3.8'
services:
    proxy-manager:
        build: .
        ports:
            - "8000:8000"
        environment:
            - REDIS_URL=redis://redis:6379
            - DATABASE_URL=postgresql://user:pass@db:5432/proxy_manager
            - LOG_LEVEL=INFO
        depends_on:
            - redis
            - db
        volumes:
            - ./config:/app/config
            - ./logs:/app/logs

    redis:
        image: redis:7-alpine
        ports:
            - "6379:6379"
        volumes:
            - redis_data:/data

    db:
        image: postgres:13-alpine
        environment:
            - POSTGRES_DB=proxy_manager
            - POSTGRES_USER=user
            - POSTGRES_PASSWORD=pass
        volumes:
            - pg_data:/var/lib/postgresql/data

    monitoring:
        image: grafana/grafana:9.0.0
        ports:
            - "3000:3000"
        environment:
            - GF_SECURITY_ADMIN_PASSWORD=admin
        volumes:
            - grafana_data:/var/lib/grafana

volumes:
    redis_data:
    pg_data:
    grafana_data:
```

### 5.2 é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# config/proxy-manager.yaml
sources:
    free:
        - url: "https://api.proxyscrape.com/v2/?request=getproxies"
            enabled: true
            interval: 3600
        - url: "https://www.sslproxies.org"
            enabled: true
            interval: 1800
    paid:
        - name: "bright_data"
            api_key: "${BRIGHT_DATA_API_KEY}"
            enabled: true
            plan: "business"
        - name: "oxylabs"
            api_key: "${OXYLABS_API_KEY}"
            enabled: false

validation:
    test_urls:
        - "http://httpbin.org/ip"
        - "https://www.google.com"
        - "https://www.amazon.com"
    timeout: 10
    concurrent_tests: 20
    validation_interval: 300

performance:
    min_success_rate: 0.6
    max_response_time: 5.0
    recycle_interval: 3600
    blacklist_threshold: 0.3

monitoring:
    enabled: true
    prometheus_port: 9090
    grafana_dashboard: true
    alert_rules:
        - alert: LowSuccessRate
            expr: success_rate < 0.5
            for: 5m
            labels:
                severity: warning
            annotations:
                summary: "ä»£ç†æˆåŠŸç‡éä½"
        - alert: HighResponseTime
            expr: avg_response_time > 3.0
            for: 10m
            labels:
                severity: critical
```

## 6. å®¢æˆ¶ç«¯ä½¿ç”¨ç¤ºä¾‹

### 6.1 Python å®¢æˆ¶ç«¯

```python
import aiohttp
import asyncio
from proxy_manager_client import ProxyManagerClient


async def main():
    client = ProxyManagerClient("http://proxy-manager:8000")
    proxy = await client.get_proxy(
        target_url="https://www.amazon.com",
        min_speed="fast",
        country="us",
        anonymity="elite"
    )
    if proxy:
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://www.amazon.com/product/123",
                    proxy=proxy.url,
                    timeout=30
                ) as response:
                    if response.status == 200:
                        data = await response.text()
                        await client.report_performance(
                            proxy.id,
                            success=True,
                            response_time=1.5,
                            bandwidth_used=len(data) / 1024 / 1024
                        )
                    else:
                        await client.report_performance(
                            proxy.id,
                            success=False,
                            response_time=30.0
                        )
        except Exception:
            await client.report_performance(
                proxy.id,
                success=False,
                response_time=30.0
            )
    else:
        print("æ²’æœ‰å¯ç”¨çš„åˆé©ä»£ç†")


if __name__ == "__main__":
    asyncio.run(main())
```

## 7. ç³»çµ±ç‰¹è‰²èˆ‡å„ªå‹¢

### 7.1 æ ¸å¿ƒå„ªå‹¢

1. æ™ºèƒ½èª¿åº¦ï¼šåŸºæ–¼æ©Ÿå™¨å­¸ç¿’çš„ä»£ç†é¸æ“‡ç®—æ³•  
2. å¤šæºé›†æˆï¼šæ”¯æŒå…è²»ã€ä»˜è²»ã€è‡ªå»ºä»£ç†æº  
3. å¯¦æ™‚ç›£æ§ï¼šå®Œæ•´çš„æ€§èƒ½ç›£æ§å’Œå‘Šè­¦ç³»çµ±  
4. å½ˆæ€§æ“´å±•ï¼šæ”¯æŒæ°´å¹³æ“´å±•å’Œè² è¼‰å‡è¡¡  
5. å®‰å…¨å¯é ï¼šå…§ç½®é»‘åå–®å’Œè‡ªå‹•æ•…éšœè½‰ç§»

### 7.2 æ€§èƒ½æŒ‡æ¨™

- âœ… 99.9% æœå‹™å¯ç”¨æ€§  
- âœ… <100ms ä»£ç†é¸æ“‡å»¶é²  
- âœ… æ”¯æŒ 10,000+ ä¸¦ç™¼é€£æ¥  
- âœ… å¯¦æ™‚æ€§èƒ½ç›£æ§  
- âœ… è‡ªå‹•æ“´å®¹ç¸®å®¹

é€™å€‹è¨­è¨ˆæä¾›äº†ä¼æ¥­ç´šçš„ä»£ç†ç®¡ç†è§£æ±ºæ–¹æ¡ˆï¼Œå…¼å…·é«˜æ€§èƒ½ã€é«˜å¯ç”¨æ€§å’Œæ˜“ç”¨æ€§ã€‚

