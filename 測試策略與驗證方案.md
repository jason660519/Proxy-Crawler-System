# JasonSpider æ¸¬è©¦ç­–ç•¥èˆ‡é©—è­‰æ–¹æ¡ˆ

**åˆ¶å®šæ™‚é–“**: 2025-01-07  
**é©ç”¨ç¯„åœ**: ä»£ç†æŠ“å–ã€ETL æµç¨‹ã€ç³»çµ±æ•´åˆæ¸¬è©¦  
**æ¸¬è©¦ç›®æ¨™**: é©—è­‰ç³»çµ±åŠŸèƒ½å®Œæ•´æ€§ã€æ•¸æ“šå“è³ªã€ETL è¦ç¯„éµå®ˆ

---

## ğŸ¯ æ¸¬è©¦ç›®æ¨™

### ä¸»è¦ç›®æ¨™

1. **é©—è­‰ä»£ç†æŠ“å–åŠŸèƒ½**: ç¢ºèªç³»çµ±èƒ½æˆåŠŸå¾å¤šå€‹ä¾†æºç²å–ä»£ç†
2. **æª¢æŸ¥æ–‡ä»¶ç”Ÿæˆ**: é©—è­‰ ETL æµç¨‹èƒ½æ­£ç¢ºç”Ÿæˆå„ç¨®æ ¼å¼çš„è¼¸å‡ºæ–‡ä»¶
3. **éµå®ˆ ETL è¦ç¯„**: ç¢ºä¿æ•¸æ“šè™•ç†æµç¨‹ç¬¦åˆè¨­è¨ˆè¦ç¯„
4. **ç³»çµ±æ•´åˆæ¸¬è©¦**: é©—è­‰å„æ¨¡çµ„é–“å”åŒå·¥ä½œæ­£å¸¸

### æˆåŠŸæ¨™æº–

- ä»£ç†æŠ“å–æˆåŠŸç‡ â‰¥ 70%
- æ–‡ä»¶ç”Ÿæˆå®Œæ•´æ€§ 100%
- ETL æµç¨‹å„éšæ®µæ­£å¸¸åŸ·è¡Œ
- ç³»çµ±ç©©å®šé‹è¡Œ â‰¥ 30 åˆ†é˜

---

## ğŸ“‹ æ¸¬è©¦è¨ˆåŠƒ

### éšæ®µ 1: åŸºç¤åŠŸèƒ½æ¸¬è©¦ (30 åˆ†é˜)

#### 1.1 ç³»çµ±å•Ÿå‹•æ¸¬è©¦

```bash
# æ¸¬è©¦ Docker æœå‹™å•Ÿå‹•
docker-compose up -d

# é©—è­‰æœå‹™å¥åº·ç‹€æ…‹
curl http://localhost:8000/health
curl http://localhost:8001/health

# æª¢æŸ¥è³‡æ–™åº«é€£æ¥
docker-compose exec postgres_db pg_isready -U proxyadmin
```

#### 1.2 é…ç½®é©—è­‰æ¸¬è©¦

```python
# æ¸¬è©¦é…ç½®åŠ è¼‰
python -c "
from src.proxy_manager.config import get_config
config = get_config()
print('é…ç½®åŠ è¼‰æˆåŠŸ:', config)
"

# æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
python -c "
import os
print('DB_USER:', os.getenv('DB_USER'))
print('DB_PASSWORD:', os.getenv('DB_PASSWORD'))
print('DB_NAME:', os.getenv('DB_NAME'))
"
```

### éšæ®µ 2: ä»£ç†æŠ“å–æ¸¬è©¦ (45 åˆ†é˜)

#### 2.1 å–®ä¸€ä¾†æºæ¸¬è©¦

```python
# æ¸¬è©¦ SSL Proxies æŠ“å–
python -c "
import asyncio
from src.proxy_manager.fetchers import SSLProxiesFetcher

async def test_ssl_proxies():
    fetcher = SSLProxiesFetcher()
    proxies = await fetcher.fetch_proxies(limit=10)
    print(f'SSL Proxies æŠ“å–æˆåŠŸ: {len(proxies)} å€‹ä»£ç†')
    for proxy in proxies[:3]:
        print(f'  - {proxy.host}:{proxy.port} ({proxy.protocol})')

asyncio.run(test_ssl_proxies())
"
```

#### 2.2 å¤šä¾†æºæ•´åˆæ¸¬è©¦

```python
# æ¸¬è©¦æ‰€æœ‰ä¾†æºæŠ“å–
python -c "
import asyncio
from src.proxy_manager.manager import ProxyManager

async def test_all_sources():
    manager = ProxyManager()
    await manager.start()

    # æ¸¬è©¦åŸºæœ¬æŠ“å–
    proxies = await manager.fetch_proxies()
    print(f'ç¸½å…±æŠ“å–: {len(proxies)} å€‹ä»£ç†')

    # æŒ‰ä¾†æºçµ±è¨ˆ
    sources = {}
    for proxy in proxies:
        source = getattr(proxy, 'source', 'unknown')
        sources[source] = sources.get(source, 0) + 1

    print('æŒ‰ä¾†æºçµ±è¨ˆ:')
    for source, count in sources.items():
        print(f'  {source}: {count} å€‹')

    await manager.stop()

asyncio.run(test_all_sources())
"
```

#### 2.3 é«˜ç´šç²å–å™¨æ¸¬è©¦

```python
# æ¸¬è©¦é«˜ç´šç²å–å™¨
python -c "
import asyncio
from src.proxy_manager.advanced_fetchers import AdvancedProxyFetcherManager

async def test_advanced_fetchers():
    config = {
        'proxyscrape_api_key': None,  # å¦‚æœæœ‰ API é‡‘é‘°
        'github_token': None,
        'shodan_api_key': None
    }

    manager = AdvancedProxyFetcherManager(config)

    # æ¸¬è©¦ GitHub ä¾†æº
    github_proxies = await manager.fetch_github_proxies()
    print(f'GitHub ä»£ç†: {len(github_proxies)} å€‹')

    # æ¸¬è©¦ ProxyScrape
    proxyscrape_proxies = await manager.fetch_proxyscrape_proxies()
    print(f'ProxyScrape ä»£ç†: {len(proxyscrape_proxies)} å€‹')

asyncio.run(test_advanced_fetchers())
"
```

### éšæ®µ 3: ETL æµç¨‹æ¸¬è©¦ (60 åˆ†é˜)

#### 3.1 æ•¸æ“šæå–æ¸¬è©¦

```python
# æ¸¬è©¦ ETL æ•¸æ“šæå–
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_extract():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # æ¸¬è©¦æå–éšæ®µ
    result = await pipeline.extract_proxies()
    print(f'ETL æå–å®Œæˆ: {result.total_records} å€‹è¨˜éŒ„')
    print(f'æˆåŠŸ: {result.successful_records}, å¤±æ•—: {result.failed_records}')
    print(f'æˆåŠŸç‡: {result.success_rate:.2%}')

asyncio.run(test_etl_extract())
"
```

#### 3.2 æ•¸æ“šè½‰æ›æ¸¬è©¦

```python
# æ¸¬è©¦æ•¸æ“šè½‰æ›
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_transform():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # å…ˆæå–æ•¸æ“š
    extract_result = await pipeline.extract_proxies()

    # æ¸¬è©¦è½‰æ›éšæ®µ
    transform_result = await pipeline.transform_proxies(extract_result.data)
    print(f'ETL è½‰æ›å®Œæˆ: {transform_result.total_records} å€‹è¨˜éŒ„')
    print(f'æˆåŠŸ: {transform_result.successful_records}, å¤±æ•—: {transform_result.failed_records}')
    print(f'æˆåŠŸç‡: {transform_result.success_rate:.2%}')

asyncio.run(test_etl_transform())
"
```

#### 3.3 æ•¸æ“šé©—è­‰æ¸¬è©¦

```python
# æ¸¬è©¦æ•¸æ“šé©—è­‰
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_validate():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # å…ˆæå–å’Œè½‰æ›æ•¸æ“š
    extract_result = await pipeline.extract_proxies()
    transform_result = await pipeline.transform_proxies(extract_result.data)

    # æ¸¬è©¦é©—è­‰éšæ®µ
    validate_result = await pipeline.validate_proxies(transform_result.data)
    print(f'ETL é©—è­‰å®Œæˆ: {validate_result.total_records} å€‹è¨˜éŒ„')
    print(f'æˆåŠŸ: {validate_result.successful_records}, å¤±æ•—: {validate_result.failed_records}')
    print(f'æˆåŠŸç‡: {validate_result.success_rate:.2%}')

asyncio.run(test_etl_validate())
"
```

#### 3.4 æ•¸æ“šåŠ è¼‰æ¸¬è©¦

```python
# æ¸¬è©¦æ•¸æ“šåŠ è¼‰
python -c "
import asyncio
from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

async def test_etl_load():
    config = ETLConfig()
    pipeline = ProxyETLPipeline(config)

    # åŸ·è¡Œå®Œæ•´ ETL æµç¨‹
    result = await pipeline.run_full_etl()
    print(f'ETL å®Œæ•´æµç¨‹å®Œæˆ: {result.total_records} å€‹è¨˜éŒ„')
    print(f'æˆåŠŸ: {result.successful_records}, å¤±æ•—: {result.failed_records}')
    print(f'æˆåŠŸç‡: {result.success_rate:.2%}')

asyncio.run(test_etl_load())
"
```

### éšæ®µ 4: æ–‡ä»¶ç”Ÿæˆé©—è­‰ (30 åˆ†é˜)

#### 4.1 æª¢æŸ¥è¼¸å‡ºæ–‡ä»¶

```bash
# æª¢æŸ¥ ETL è¼¸å‡ºæ–‡ä»¶
ls -la data/raw/
ls -la data/processed/
ls -la data/validated/
ls -la data/reports/

# æª¢æŸ¥æ–‡ä»¶å…§å®¹
echo "=== Raw æ•¸æ“š ==="
head -20 data/raw/proxies_raw_*.json

echo "=== Processed æ•¸æ“š ==="
head -20 data/processed/proxies_processed_*.json

echo "=== Validated æ•¸æ“š ==="
head -20 data/validated/proxies_validated_*.json

echo "=== å ±å‘Šæ–‡ä»¶ ==="
head -20 data/reports/proxy_etl_report_*.md
```

#### 4.2 é©—è­‰æ–‡ä»¶æ ¼å¼

```python
# é©—è­‰ JSON æ–‡ä»¶æ ¼å¼
python -c "
import json
from pathlib import Path

def validate_json_files():
    data_dir = Path('data')

    # æª¢æŸ¥ raw æ–‡ä»¶
    raw_files = list(data_dir.glob('raw/*.json'))
    print(f'Raw JSON æ–‡ä»¶: {len(raw_files)} å€‹')
    for file in raw_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f'  âœ… {file.name}: {len(data.get("proxies", []))} å€‹ä»£ç†')
        except Exception as e:
            print(f'  âŒ {file.name}: æ ¼å¼éŒ¯èª¤ - {e}')

    # æª¢æŸ¥ processed æ–‡ä»¶
    processed_files = list(data_dir.glob('processed/*.json'))
    print(f'Processed JSON æ–‡ä»¶: {len(processed_files)} å€‹')
    for file in processed_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f'  âœ… {file.name}: {len(data.get("proxies", []))} å€‹ä»£ç†')
        except Exception as e:
            print(f'  âŒ {file.name}: æ ¼å¼éŒ¯èª¤ - {e}')

validate_json_files()
"
```

### éšæ®µ 5: ç³»çµ±æ•´åˆæ¸¬è©¦ (45 åˆ†é˜)

#### 5.1 API ç«¯é»æ¸¬è©¦

```bash
# æ¸¬è©¦ä¸»è¦ API ç«¯é»
echo "=== ç³»çµ±ç‹€æ…‹ ==="
curl -s http://localhost:8000/ | jq .

echo "=== å¥åº·æª¢æŸ¥ ==="
curl -s http://localhost:8000/health | jq .

echo "=== ä»£ç†çµ±è¨ˆ ==="
curl -s http://localhost:8000/api/stats | jq .

echo "=== ä»£ç†åˆ—è¡¨ ==="
curl -s "http://localhost:8000/api/proxies?limit=5" | jq .
```

#### 5.2 ä»£ç†æ± ç®¡ç†æ¸¬è©¦

```python
# æ¸¬è©¦ä»£ç†æ± ç®¡ç†
python -c "
import asyncio
from src.proxy_manager.manager import ProxyManager

async def test_pool_management():
    manager = ProxyManager()
    await manager.start()

    # ç²å–ä»£ç†çµ±è¨ˆ
    stats = await manager.get_statistics()
    print('ä»£ç†æ± çµ±è¨ˆ:')
    print(f'  ç¸½ä»£ç†æ•¸: {stats.get("total_proxies", 0)}')
    print(f'  ç†±æ± : {stats.get("hot_pool", 0)}')
    print(f'  æº«æ± : {stats.get("warm_pool", 0)}')
    print(f'  å†·æ± : {stats.get("cold_pool", 0)}')
    print(f'  é»‘åå–®: {stats.get("blacklist", 0)}')

    # æ¸¬è©¦ä»£ç†ç²å–
    proxies = await manager.get_proxies(limit=10)
    print(f'ç²å–ä»£ç†: {len(proxies)} å€‹')

    await manager.stop()

asyncio.run(test_pool_management())
"
```

#### 5.3 è³‡æ–™åº«é€£æ¥æ¸¬è©¦

```python
# æ¸¬è©¦è³‡æ–™åº«é€£æ¥
python -c "
import asyncio
import asyncpg

async def test_database_connection():
    try:
        # æ¸¬è©¦ PostgreSQL é€£æ¥
        conn = await asyncpg.connect(
            host='localhost',
            port=5432,
            user='proxyadmin',
            password='proxyadmin123',
            database='proxypool'
        )

        # æ¸¬è©¦æŸ¥è©¢
        result = await conn.fetchval('SELECT version()')
        print(f'âœ… PostgreSQL é€£æ¥æˆåŠŸ: {result}')

        await conn.close()

    except Exception as e:
        print(f'âŒ PostgreSQL é€£æ¥å¤±æ•—: {e}')

asyncio.run(test_database_connection())
"
```

### éšæ®µ 6: æ€§èƒ½å£“åŠ›æ¸¬è©¦ (30 åˆ†é˜)

#### 6.1 ä¸¦ç™¼æ¸¬è©¦

```python
# æ¸¬è©¦ä¸¦ç™¼è™•ç†èƒ½åŠ›
python -c "
import asyncio
import time
from src.proxy_manager.manager import ProxyManager

async def test_concurrent_processing():
    manager = ProxyManager()
    await manager.start()

    # æ¸¬è©¦ä¸¦ç™¼ä»£ç†ç²å–
    start_time = time.time()

    tasks = []
    for i in range(5):  # 5 å€‹ä¸¦ç™¼ä»»å‹™
        task = manager.fetch_proxies()
        tasks.append(task)

    results = await asyncio.gather(*tasks)
    end_time = time.time()

    total_proxies = sum(len(result) for result in results)
    print(f'ä¸¦ç™¼æ¸¬è©¦å®Œæˆ: {total_proxies} å€‹ä»£ç†')
    print(f'è™•ç†æ™‚é–“: {end_time - start_time:.2f} ç§’')
    print(f'å¹³å‡é€Ÿåº¦: {total_proxies / (end_time - start_time):.2f} ä»£ç†/ç§’')

    await manager.stop()

asyncio.run(test_concurrent_processing())
"
```

#### 6.2 å…§å­˜ä½¿ç”¨æ¸¬è©¦

```python
# æ¸¬è©¦å…§å­˜ä½¿ç”¨
python -c "
import psutil
import os
import time
from src.proxy_manager.manager import ProxyManager

async def test_memory_usage():
    process = psutil.Process(os.getpid())

    # è¨˜éŒ„åˆå§‹å…§å­˜
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'åˆå§‹å…§å­˜ä½¿ç”¨: {initial_memory:.2f} MB')

    manager = ProxyManager()
    await manager.start()

    # è¨˜éŒ„å•Ÿå‹•å¾Œå…§å­˜
    startup_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'å•Ÿå‹•å¾Œå…§å­˜ä½¿ç”¨: {startup_memory:.2f} MB')

    # åŸ·è¡Œä»£ç†ç²å–
    proxies = await manager.fetch_proxies()

    # è¨˜éŒ„ç²å–å¾Œå…§å­˜
    after_fetch_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'ç²å–å¾Œå…§å­˜ä½¿ç”¨: {after_fetch_memory:.2f} MB')
    print(f'å…§å­˜å¢é•·: {after_fetch_memory - startup_memory:.2f} MB')

    await manager.stop()

asyncio.run(test_memory_usage())
"
```

---

## ğŸ“Š æ¸¬è©¦çµæœè©•ä¼°

### è©•ä¼°æ¨™æº–

#### åŠŸèƒ½å®Œæ•´æ€§ (40%)

- ä»£ç†æŠ“å–æˆåŠŸç‡ â‰¥ 70%
- æ–‡ä»¶ç”Ÿæˆå®Œæ•´æ€§ 100%
- ETL æµç¨‹å„éšæ®µæ­£å¸¸åŸ·è¡Œ
- API ç«¯é»å¯ç”¨æ€§ 100%

#### æ•¸æ“šå“è³ª (30%)

- ä»£ç†é©—è­‰æº–ç¢ºæ€§ â‰¥ 80%
- æ•¸æ“šæ ¼å¼æ­£ç¢ºæ€§ 100%
- é‡è¤‡æ•¸æ“šç‡ â‰¤ 5%
- åœ°ç†ä½ç½®ä¿¡æ¯å®Œæ•´æ€§ â‰¥ 60%

#### ç³»çµ±æ€§èƒ½ (20%)

- éŸ¿æ‡‰æ™‚é–“ â‰¤ 2 ç§’
- å…§å­˜ä½¿ç”¨ â‰¤ 1GB
- ä¸¦ç™¼è™•ç†èƒ½åŠ› â‰¥ 50 å€‹è«‹æ±‚/ç§’
- ç³»çµ±ç©©å®šæ€§ â‰¥ 30 åˆ†é˜

#### éŒ¯èª¤è™•ç† (10%)

- ç•°å¸¸æ•ç²ç‡ 100%
- éŒ¯èª¤æ¢å¾©èƒ½åŠ› â‰¥ 90%
- æ—¥èªŒè¨˜éŒ„å®Œæ•´æ€§ 100%
- ç›£æ§å‘Šè­¦åŠæ™‚æ€§ 100%

### æ¸¬è©¦å ±å‘Šæ¨¡æ¿

```markdown
# æ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ¦‚æ³

- æ¸¬è©¦æ™‚é–“: 2025-01-07
- æ¸¬è©¦ç’°å¢ƒ: Docker å®¹å™¨
- æ¸¬è©¦ç¯„åœ: å®Œæ•´ç³»çµ±åŠŸèƒ½

## æ¸¬è©¦çµæœ

### åŠŸèƒ½æ¸¬è©¦

- âœ… ä»£ç†æŠ“å–: æˆåŠŸ (85% æˆåŠŸç‡)
- âœ… æ–‡ä»¶ç”Ÿæˆ: æˆåŠŸ (100% å®Œæ•´æ€§)
- âœ… ETL æµç¨‹: æˆåŠŸ (90% æˆåŠŸç‡)
- âœ… API æœå‹™: æˆåŠŸ (100% å¯ç”¨æ€§)

### æ€§èƒ½æ¸¬è©¦

- âœ… éŸ¿æ‡‰æ™‚é–“: 1.2 ç§’ (ç›®æ¨™ â‰¤ 2 ç§’)
- âœ… å…§å­˜ä½¿ç”¨: 512MB (ç›®æ¨™ â‰¤ 1GB)
- âœ… ä¸¦ç™¼è™•ç†: 75 è«‹æ±‚/ç§’ (ç›®æ¨™ â‰¥ 50)
- âœ… ç³»çµ±ç©©å®šæ€§: 45 åˆ†é˜ (ç›®æ¨™ â‰¥ 30 åˆ†é˜)

### æ•¸æ“šå“è³ª

- âœ… ä»£ç†é©—è­‰: 82% æº–ç¢ºæ€§ (ç›®æ¨™ â‰¥ 80%)
- âœ… æ•¸æ“šæ ¼å¼: 100% æ­£ç¢ºæ€§
- âœ… é‡è¤‡æ•¸æ“š: 3% (ç›®æ¨™ â‰¤ 5%)
- âœ… åœ°ç†ä½ç½®: 65% å®Œæ•´æ€§ (ç›®æ¨™ â‰¥ 60%)

## å•é¡Œèˆ‡å»ºè­°

1. ä»£ç†é©—è­‰æº–ç¢ºæ€§éœ€è¦æå‡
2. åœ°ç†ä½ç½®ä¿¡æ¯éœ€è¦è£œå……
3. å…§å­˜ä½¿ç”¨å¯ä»¥é€²ä¸€æ­¥å„ªåŒ–

## ç¸½é«”è©•ä¼°

ç³»çµ±åŠŸèƒ½åŸºæœ¬å®Œæ•´ï¼Œæ€§èƒ½è¡¨ç¾è‰¯å¥½ï¼Œå»ºè­°é€²è¡Œå„ªåŒ–å¾Œæ­£å¼éƒ¨ç½²ã€‚
```

---

## ğŸš€ åŸ·è¡Œå»ºè­°

### ç«‹å³åŸ·è¡Œ

1. **å•Ÿå‹•æ¸¬è©¦ç’°å¢ƒ**: ç¢ºä¿ Docker æœå‹™æ­£å¸¸é‹è¡Œ
2. **åŸ·è¡ŒåŸºç¤æ¸¬è©¦**: é©—è­‰ç³»çµ±å•Ÿå‹•å’Œé…ç½®
3. **é€²è¡ŒåŠŸèƒ½æ¸¬è©¦**: æ¸¬è©¦ä»£ç†æŠ“å–å’Œ ETL æµç¨‹

### æŒçºŒç›£æ§

1. **æ€§èƒ½ç›£æ§**: ç›£æ§ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
2. **éŒ¯èª¤è¿½è¹¤**: è¨˜éŒ„å’Œåˆ†æéŒ¯èª¤æ—¥èªŒ
3. **æ•¸æ“šå“è³ª**: å®šæœŸæª¢æŸ¥æ•¸æ“šå“è³ªæŒ‡æ¨™

### å„ªåŒ–æ”¹é€²

1. **æ€§èƒ½å„ªåŒ–**: æ ¹æ“šæ¸¬è©¦çµæœèª¿æ•´åƒæ•¸
2. **åŠŸèƒ½å®Œå–„**: ä¿®å¾©ç™¼ç¾çš„å•é¡Œ
3. **æ–‡æª”æ›´æ–°**: æ›´æ–°æ¸¬è©¦æ–‡æª”å’Œæ“ä½œæŒ‡å—

---

**æ¸¬è©¦ç­–ç•¥åˆ¶å®šå®Œæˆ**  
**å»ºè­°åŸ·è¡Œæ™‚é–“**: 3-4 å°æ™‚  
**é æœŸæˆåŠŸç‡**: 85% ä»¥ä¸Š

