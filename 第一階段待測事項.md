# 第一階段待測事項

**文檔生成時間**: 2025-01-07  
**測試範圍**: 代理抓取、ETL 流程、系統整合  
**預估測試時間**: 3-4 小時  
**測試環境**: Docker 容器化環境

---

## 🎯 測試目標

### 主要目標

1. **驗證代理抓取功能**: 確認系統能成功從多個來源獲取代理
2. **檢查文件生成**: 驗證 ETL 流程能正確生成各種格式的輸出文件
3. **遵守 ETL 規範**: 確保數據處理流程符合設計規範
4. **系統整合測試**: 驗證各模組間協同工作正常

### 成功標準

- 代理抓取成功率 ≥ 70%
- 文件生成完整性 100%
- ETL 流程各階段正常執行
- 系統穩定運行 ≥ 30 分鐘

---

## 📋 測試項目清單

### 階段 1: 基礎功能測試 (30 分鐘)

#### 1.1 系統啟動測試

- [ ] **Docker 服務啟動**

  ```bash
  docker-compose up -d
  ```

  - 檢查所有服務是否正常啟動
  - 驗證服務健康狀態

- [ ] **服務健康檢查**

  ```bash
  curl http://localhost:8000/health
  curl http://localhost:8001/health
  ```

  - 主服務 (port 8000) 健康檢查
  - HTML to Markdown 服務 (port 8001) 健康檢查

- [ ] **資料庫連接測試**
  ```bash
  docker-compose exec postgres_db pg_isready -U proxyadmin
  ```
  - PostgreSQL 資料庫連接狀態
  - Redis 快取服務狀態

#### 1.2 配置驗證測試

- [ ] **配置加載測試**

  ```python
  python -c "
  from src.proxy_manager.config import get_config
  config = get_config()
  print('配置加載成功:', config)
  "
  ```

  - 驗證配置模組正常加載
  - 檢查配置參數完整性

- [ ] **環境變數檢查**
  ```python
  python -c "
  import os
  print('DB_USER:', os.getenv('DB_USER'))
  print('DB_PASSWORD:', os.getenv('DB_PASSWORD'))
  print('DB_NAME:', os.getenv('DB_NAME'))
  "
  ```
  - 檢查必需環境變數
  - 驗證資料庫連接參數

### 階段 2: 代理抓取測試 (45 分鐘)

#### 2.1 單一來源測試

- [ ] **SSL Proxies 抓取測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.fetchers import SSLProxiesFetcher

  async def test_ssl_proxies():
      fetcher = SSLProxiesFetcher()
      proxies = await fetcher.fetch_proxies(limit=10)
      print(f'SSL Proxies 抓取成功: {len(proxies)} 個代理')
      for proxy in proxies[:3]:
          print(f'  - {proxy.host}:{proxy.port} ({proxy.protocol})')

  asyncio.run(test_ssl_proxies())
  "
  ```

  - 測試 SSL Proxies 來源抓取
  - 驗證代理數據格式正確性

- [ ] **Free Proxy List 抓取測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.fetchers import FreeProxyListFetcher

  async def test_free_proxy_list():
      fetcher = FreeProxyListFetcher()
      proxies = await fetcher.fetch_proxies(limit=10)
      print(f'Free Proxy List 抓取成功: {len(proxies)} 個代理')
      for proxy in proxies[:3]:
          print(f'  - {proxy.host}:{proxy.port} ({proxy.protocol})')

  asyncio.run(test_free_proxy_list())
  "
  ```

  - 測試 Free Proxy List 來源抓取
  - 驗證代理數據完整性

- [ ] **Geonode 抓取測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.fetchers import GeonodeFetcher

  async def test_geonode():
      fetcher = GeonodeFetcher()
      proxies = await fetcher.fetch_proxies(limit=10)
      print(f'Geonode 抓取成功: {len(proxies)} 個代理')
      for proxy in proxies[:3]:
          print(f'  - {proxy.host}:{proxy.port} ({proxy.protocol})')

  asyncio.run(test_geonode())
  "
  ```

  - 測試 Geonode 來源抓取
  - 驗證代理數據品質

#### 2.2 多來源整合測試

- [ ] **代理管理器整合測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.manager import ProxyManager

  async def test_all_sources():
      manager = ProxyManager()
      await manager.start()

      # 測試基本抓取
      proxies = await manager.fetch_proxies()
      print(f'總共抓取: {len(proxies)} 個代理')

      # 按來源統計
      sources = {}
      for proxy in proxies:
          source = getattr(proxy, 'source', 'unknown')
          sources[source] = sources.get(source, 0) + 1

      print('按來源統計:')
      for source, count in sources.items():
          print(f'  {source}: {count} 個')

      await manager.stop()

  asyncio.run(test_all_sources())
  "
  ```

  - 測試所有來源整合抓取
  - 驗證代理數據統計

#### 2.3 高級獲取器測試

- [ ] **GitHub 代理專案測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.advanced_fetchers import AdvancedProxyFetcherManager

  async def test_github_fetchers():
      config = {
          'github_token': None,  # 如果有 API 金鑰
      }

      manager = AdvancedProxyFetcherManager(config)
      github_proxies = await manager.fetch_github_proxies()
      print(f'GitHub 代理: {len(github_proxies)} 個')

  asyncio.run(test_github_fetchers())
  "
  ```

  - 測試 GitHub 代理專案抓取
  - 驗證高級獲取器功能

- [ ] **ProxyScrape API 測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.advanced_fetchers import AdvancedProxyFetcherManager

  async def test_proxyscrape():
      config = {
          'proxyscrape_api_key': None,  # 如果有 API 金鑰
      }

      manager = AdvancedProxyFetcherManager(config)
      proxyscrape_proxies = await manager.fetch_proxyscrape_proxies()
      print(f'ProxyScrape 代理: {len(proxyscrape_proxies)} 個')

  asyncio.run(test_proxyscrape())
  "
  ```

  - 測試 ProxyScrape API 抓取
  - 驗證 API 整合功能

### 階段 3: ETL 流程測試 (60 分鐘)

#### 3.1 數據提取測試

- [ ] **ETL 數據提取測試**

  ```python
  python -c "
  import asyncio
  from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

  async def test_etl_extract():
      config = ETLConfig()
      pipeline = ProxyETLPipeline(config)

      # 測試提取階段
      result = await pipeline.extract_proxies()
      print(f'ETL 提取完成: {result.total_records} 個記錄')
      print(f'成功: {result.successful_records}, 失敗: {result.failed_records}')
      print(f'成功率: {result.success_rate:.2%}')

  asyncio.run(test_etl_extract())
  "
  ```

  - 測試 ETL 數據提取階段
  - 驗證提取成功率

#### 3.2 數據轉換測試

- [ ] **ETL 數據轉換測試**

  ```python
  python -c "
  import asyncio
  from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

  async def test_etl_transform():
      config = ETLConfig()
      pipeline = ProxyETLPipeline(config)

      # 先提取數據
      extract_result = await pipeline.extract_proxies()

      # 測試轉換階段
      transform_result = await pipeline.transform_proxies(extract_result.data)
      print(f'ETL 轉換完成: {transform_result.total_records} 個記錄')
      print(f'成功: {transform_result.successful_records}, 失敗: {transform_result.failed_records}')
      print(f'成功率: {transform_result.success_rate:.2%}')

  asyncio.run(test_etl_transform())
  "
  ```

  - 測試 ETL 數據轉換階段
  - 驗證轉換成功率

#### 3.3 數據驗證測試

- [ ] **ETL 數據驗證測試**

  ```python
  python -c "
  import asyncio
  from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

  async def test_etl_validate():
      config = ETLConfig()
      pipeline = ProxyETLPipeline(config)

      # 先提取和轉換數據
      extract_result = await pipeline.extract_proxies()
      transform_result = await pipeline.transform_proxies(extract_result.data)

      # 測試驗證階段
      validate_result = await pipeline.validate_proxies(transform_result.data)
      print(f'ETL 驗證完成: {validate_result.total_records} 個記錄')
      print(f'成功: {validate_result.successful_records}, 失敗: {validate_result.failed_records}')
      print(f'成功率: {validate_result.success_rate:.2%}')

  asyncio.run(test_etl_validate())
  "
  ```

  - 測試 ETL 數據驗證階段
  - 驗證代理連通性

#### 3.4 數據加載測試

- [ ] **ETL 完整流程測試**

  ```python
  python -c "
  import asyncio
  from src.etl.proxy_etl_pipeline import ProxyETLPipeline, ETLConfig

  async def test_etl_full():
      config = ETLConfig()
      pipeline = ProxyETLPipeline(config)

      # 執行完整 ETL 流程
      result = await pipeline.run_full_etl()
      print(f'ETL 完整流程完成: {result.total_records} 個記錄')
      print(f'成功: {result.successful_records}, 失敗: {result.failed_records}')
      print(f'成功率: {result.success_rate:.2%}')

  asyncio.run(test_etl_full())
  "
  ```

  - 測試 ETL 完整流程
  - 驗證數據加載到資料庫

### 階段 4: 文件生成驗證 (30 分鐘)

#### 4.1 輸出文件檢查

- [ ] **檢查 ETL 輸出目錄**

  ```bash
  ls -la data/raw/
  ls -la data/processed/
  ls -la data/validated/
  ls -la data/reports/
  ```

  - 檢查各階段輸出目錄
  - 驗證文件存在性

- [ ] **檢查文件內容**

  ```bash
  echo "=== Raw 數據 ==="
  head -20 data/raw/proxies_raw_*.json

  echo "=== Processed 數據 ==="
  head -20 data/processed/proxies_processed_*.json

  echo "=== Validated 數據 ==="
  head -20 data/validated/proxies_validated_*.json

  echo "=== 報告文件 ==="
  head -20 data/reports/proxy_etl_report_*.md
  ```

  - 檢查各階段文件內容
  - 驗證數據格式正確性

#### 4.2 文件格式驗證

- [ ] **JSON 文件格式驗證**

  ```python
  python -c "
  import json
  from pathlib import Path

  def validate_json_files():
      data_dir = Path('data')

      # 檢查 raw 文件
      raw_files = list(data_dir.glob('raw/*.json'))
      print(f'Raw JSON 文件: {len(raw_files)} 個')
      for file in raw_files:
          try:
              with open(file, 'r', encoding='utf-8') as f:
                  data = json.load(f)
              print(f'  ✅ {file.name}: {len(data.get(\"proxies\", []))} 個代理')
          except Exception as e:
              print(f'  ❌ {file.name}: 格式錯誤 - {e}')

      # 檢查 processed 文件
      processed_files = list(data_dir.glob('processed/*.json'))
      print(f'Processed JSON 文件: {len(processed_files)} 個')
      for file in processed_files:
          try:
              with open(file, 'r', encoding='utf-8') as f:
                  data = json.load(f)
              print(f'  ✅ {file.name}: {len(data.get(\"proxies\", []))} 個代理')
          except Exception as e:
              print(f'  ❌ {file.name}: 格式錯誤 - {e}')

  validate_json_files()
  "
  ```

  - 驗證 JSON 文件格式正確性
  - 檢查數據結構完整性

- [ ] **Markdown 報告驗證**

  ```python
  python -c "
  from pathlib import Path

  def validate_markdown_reports():
      data_dir = Path('data')
      report_files = list(data_dir.glob('reports/*.md'))

      print(f'Markdown 報告文件: {len(report_files)} 個')
      for file in report_files:
          try:
              with open(file, 'r', encoding='utf-8') as f:
                  content = f.read()

              # 檢查基本結構
              has_title = '# ' in content
              has_table = '|' in content
              has_stats = '統計' in content or 'statistics' in content.lower()

              print(f'  ✅ {file.name}: 標題={has_title}, 表格={has_table}, 統計={has_stats}')
          except Exception as e:
              print(f'  ❌ {file.name}: 讀取錯誤 - {e}')

  validate_markdown_reports()
  "
  ```

  - 驗證 Markdown 報告格式
  - 檢查報告內容完整性

### 階段 5: 系統整合測試 (45 分鐘)

#### 5.1 API 端點測試

- [ ] **系統狀態 API 測試**

  ```bash
  echo "=== 系統狀態 ==="
  curl -s http://localhost:8000/ | jq .

  echo "=== 健康檢查 ==="
  curl -s http://localhost:8000/health | jq .

  echo "=== 詳細狀態 ==="
  curl -s http://localhost:8000/status | jq .
  ```

  - 測試系統基本狀態 API
  - 驗證服務可用性

- [ ] **代理管理 API 測試**

  ```bash
  echo "=== 代理統計 ==="
  curl -s http://localhost:8000/api/stats | jq .

  echo "=== 代理列表 ==="
  curl -s "http://localhost:8000/api/proxies?limit=5" | jq .

  echo "=== 代理池狀態 ==="
  curl -s http://localhost:8000/api/pools | jq .
  ```

  - 測試代理管理相關 API
  - 驗證數據返回正確性

- [ ] **ETL 整合 API 測試**

  ```bash
  echo "=== ETL 狀態 ==="
  curl -s http://localhost:8000/api/etl/status | jq .

  echo "=== ETL 同步 ==="
  curl -s -X POST http://localhost:8000/api/etl/sync | jq .
  ```

  - 測試 ETL 整合 API
  - 驗證 ETL 流程觸發

#### 5.2 代理池管理測試

- [ ] **代理池統計測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.manager import ProxyManager

  async def test_pool_stats():
      manager = ProxyManager()
      await manager.start()

      # 獲取代理統計
      stats = await manager.get_statistics()
      print('代理池統計:')
      print(f'  總代理數: {stats.get(\"total_proxies\", 0)}')
      print(f'  熱池: {stats.get(\"hot_pool\", 0)}')
      print(f'  溫池: {stats.get(\"warm_pool\", 0)}')
      print(f'  冷池: {stats.get(\"cold_pool\", 0)}')
      print(f'  黑名單: {stats.get(\"blacklist\", 0)}')

      await manager.stop()

  asyncio.run(test_pool_stats())
  "
  ```

  - 測試代理池統計功能
  - 驗證池分類正確性

- [ ] **代理獲取測試**

  ```python
  python -c "
  import asyncio
  from src.proxy_manager.manager import ProxyManager

  async def test_proxy_retrieval():
      manager = ProxyManager()
      await manager.start()

      # 測試代理獲取
      proxies = await manager.get_proxies(limit=10)
      print(f'獲取代理: {len(proxies)} 個')

      # 檢查代理品質
      for proxy in proxies[:3]:
          print(f'  - {proxy.host}:{proxy.port} (評分: {getattr(proxy, \"score\", \"N/A\")})')

      await manager.stop()

  asyncio.run(test_proxy_retrieval())
  "
  ```

  - 測試代理獲取功能
  - 驗證代理品質評分

#### 5.3 資料庫連接測試

- [ ] **PostgreSQL 連接測試**

  ```python
  python -c "
  import asyncio
  import asyncpg

  async def test_postgres_connection():
      try:
          conn = await asyncpg.connect(
              host='localhost',
              port=5432,
              user='proxyadmin',
              password='proxyadmin123',
              database='proxypool'
          )

          result = await conn.fetchval('SELECT version()')
          print(f'✅ PostgreSQL 連接成功: {result}')

          await conn.close()
      except Exception as e:
          print(f'❌ PostgreSQL 連接失敗: {e}')

  asyncio.run(test_postgres_connection())
  "
  ```

  - 測試 PostgreSQL 資料庫連接
  - 驗證資料庫可用性

- [ ] **Redis 連接測試**

  ```python
  python -c "
  import asyncio
  import redis.asyncio as redis

  async def test_redis_connection():
      try:
          r = redis.Redis(host='localhost', port=6379, db=0)
          await r.ping()
          print('✅ Redis 連接成功')

          # 測試基本操作
          await r.set('test_key', 'test_value')
          value = await r.get('test_key')
          print(f'✅ Redis 操作測試: {value.decode()}')

          await r.close()
      except Exception as e:
          print(f'❌ Redis 連接失敗: {e}')

  asyncio.run(test_redis_connection())
  "
  ```

  - 測試 Redis 快取連接
  - 驗證快取操作功能

### 階段 6: 性能壓力測試 (30 分鐘)

#### 6.1 並發處理測試

- [ ] **並發代理獲取測試**

  ```python
  python -c "
  import asyncio
  import time
  from src.proxy_manager.manager import ProxyManager

  async def test_concurrent_fetch():
      manager = ProxyManager()
      await manager.start()

      # 測試並發代理獲取
      start_time = time.time()

      tasks = []
      for i in range(5):  # 5 個並發任務
          task = manager.fetch_proxies()
          tasks.append(task)

      results = await asyncio.gather(*tasks)
      end_time = time.time()

      total_proxies = sum(len(result) for result in results)
      print(f'並發測試完成: {total_proxies} 個代理')
      print(f'處理時間: {end_time - start_time:.2f} 秒')
      print(f'平均速度: {total_proxies / (end_time - start_time):.2f} 代理/秒')

      await manager.stop()

  asyncio.run(test_concurrent_fetch())
  "
  ```

  - 測試並發處理能力
  - 驗證系統性能指標

#### 6.2 內存使用測試

- [ ] **內存使用監控**

  ```python
  python -c "
  import psutil
  import os
  import time
  from src.proxy_manager.manager import ProxyManager

  async def test_memory_usage():
      process = psutil.Process(os.getpid())

      # 記錄初始內存
      initial_memory = process.memory_info().rss / 1024 / 1024  # MB
      print(f'初始內存使用: {initial_memory:.2f} MB')

      manager = ProxyManager()
      await manager.start()

      # 記錄啟動後內存
      startup_memory = process.memory_info().rss / 1024 / 1024  # MB
      print(f'啟動後內存使用: {startup_memory:.2f} MB')

      # 執行代理獲取
      proxies = await manager.fetch_proxies()

      # 記錄獲取後內存
      after_fetch_memory = process.memory_info().rss / 1024 / 1024  # MB
      print(f'獲取後內存使用: {after_fetch_memory:.2f} MB')
      print(f'內存增長: {after_fetch_memory - startup_memory:.2f} MB')

      await manager.stop()

  asyncio.run(test_memory_usage())
  "
  ```

  - 監控內存使用情況
  - 檢查內存洩漏問題

#### 6.3 系統穩定性測試

- [ ] **長時間運行測試**

  ```python
  python -c "
  import asyncio
  import time
  from src.proxy_manager.manager import ProxyManager

  async def test_long_running():
      manager = ProxyManager()
      await manager.start()

      print('開始長時間運行測試 (5 分鐘)...')
      start_time = time.time()

      try:
          # 每 30 秒執行一次代理獲取
          for i in range(10):  # 10 次循環 = 5 分鐘
              proxies = await manager.fetch_proxies()
              print(f'第 {i+1} 次獲取: {len(proxies)} 個代理')
              await asyncio.sleep(30)  # 等待 30 秒

      except KeyboardInterrupt:
          print('測試被中斷')
      finally:
          end_time = time.time()
          print(f'測試完成，總運行時間: {end_time - start_time:.2f} 秒')
          await manager.stop()

  asyncio.run(test_long_running())
  "
  ```

  - 測試系統長時間運行穩定性
  - 驗證無內存洩漏

---

## 📊 測試結果評估

### 評估標準

#### 功能完整性 (40%)

- [ ] 代理抓取成功率 ≥ 70%
- [ ] 文件生成完整性 100%
- [ ] ETL 流程各階段正常執行
- [ ] API 端點可用性 100%

#### 數據品質 (30%)

- [ ] 代理驗證準確性 ≥ 80%
- [ ] 數據格式正確性 100%
- [ ] 重複數據率 ≤ 5%
- [ ] 地理位置信息完整性 ≥ 60%

#### 系統性能 (20%)

- [ ] 響應時間 ≤ 2 秒
- [ ] 內存使用 ≤ 1GB
- [ ] 並發處理能力 ≥ 50 個請求/秒
- [ ] 系統穩定性 ≥ 30 分鐘

#### 錯誤處理 (10%)

- [ ] 異常捕獲率 100%
- [ ] 錯誤恢復能力 ≥ 90%
- [ ] 日誌記錄完整性 100%
- [ ] 監控告警及時性 100%

### 測試結果記錄

#### 功能測試結果

- [ ] 代理抓取: □ 成功 □ 失敗 (成功率: \_\_\_%)
- [ ] 文件生成: □ 成功 □ 失敗 (完整性: \_\_\_%)
- [ ] ETL 流程: □ 成功 □ 失敗 (成功率: \_\_\_%)
- [ ] API 服務: □ 成功 □ 失敗 (可用性: \_\_\_%)

#### 性能測試結果

- [ ] 響應時間: \_\_\_ 秒 (目標 ≤ 2 秒)
- [ ] 內存使用: \_\_\_ MB (目標 ≤ 1GB)
- [ ] 並發處理: \_\_\_ 請求/秒 (目標 ≥ 50)
- [ ] 系統穩定性: \_\_\_ 分鐘 (目標 ≥ 30 分鐘)

#### 數據品質結果

- [ ] 代理驗證: \_\_\_% 準確性 (目標 ≥ 80%)
- [ ] 數據格式: \_\_\_% 正確性 (目標 100%)
- [ ] 重複數據: \_\_\_% (目標 ≤ 5%)
- [ ] 地理位置: \_\_\_% 完整性 (目標 ≥ 60%)

---

## 🚨 問題記錄

### 發現的問題

1. **配置問題**

   - [ ] 問題描述: ****\_\_\_****
   - [ ] 影響範圍: ****\_\_\_****
   - [ ] 解決方案: ****\_\_\_****

2. **功能問題**

   - [ ] 問題描述: ****\_\_\_****
   - [ ] 影響範圍: ****\_\_\_****
   - [ ] 解決方案: ****\_\_\_****

3. **性能問題**

   - [ ] 問題描述: ****\_\_\_****
   - [ ] 影響範圍: ****\_\_\_****
   - [ ] 解決方案: ****\_\_\_****

4. **數據品質問題**
   - [ ] 問題描述: ****\_\_\_****
   - [ ] 影響範圍: ****\_\_\_****
   - [ ] 解決方案: ****\_\_\_****

### 改進建議

1. **短期改進** (1-2 週)

   - [ ] ***
   - [ ] ***
   - [ ] ***

2. **中期改進** (1-2 個月)

   - [ ] ***
   - [ ] ***
   - [ ] ***

3. **長期改進** (3-6 個月)
   - [ ] ***
   - [ ] ***
   - [ ] ***

---

## 📝 測試總結

### 總體評估

- [ ] 優秀 (90-100%)
- [ ] 良好 (80-89%)
- [ ] 合格 (70-79%)
- [ ] 不合格 (< 70%)

### 主要成就

1. ***
2. ***
3. ***

### 主要問題

1. ***
2. ***
3. ***

### 下一步行動

1. **立即執行**

   - [ ] ***
   - [ ] ***

2. **短期規劃**

   - [ ] ***
   - [ ] ***

3. **長期規劃**
   - [ ] ***
   - [ ] ***

---

**測試負責人**: ****\_\_\_****
**測試完成時間**: ****\_\_\_****
**測試環境**: Docker 容器化環境
**測試工具**: Python 腳本、curl、jq

---

## 📋 附錄

### 測試環境準備

```bash
# 1. 啟動 Docker 服務
docker-compose up -d

# 2. 檢查服務狀態
docker-compose ps

# 3. 查看服務日誌
docker-compose logs -f proxy_crawler

# 4. 進入容器進行測試
docker-compose exec proxy_crawler bash
```

### 常用測試命令

```bash
# 檢查服務健康狀態
curl -s http://localhost:8000/health | jq .

# 查看代理統計
curl -s http://localhost:8000/api/stats | jq .

# 檢查 ETL 狀態
curl -s http://localhost:8000/api/etl/status | jq .

# 查看資料庫連接
docker-compose exec postgres_db psql -U proxyadmin -d proxypool -c "SELECT version();"
```

### 故障排除

1. **服務無法啟動**: 檢查 Docker 和環境變數配置
2. **資料庫連接失敗**: 檢查 PostgreSQL 服務和連接參數
3. **代理抓取失敗**: 檢查網路連接和目標網站可用性
4. **ETL 流程錯誤**: 檢查數據格式和處理邏輯
5. **API 響應錯誤**: 檢查服務狀態和日誌文件
